#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# Copyright notice
# ----------------
#
# Copyright (C) 2013 Daniel Jung
# Contact: d.jung@jacobs-university.de
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the Free
# Software Foundation; either version 2 of the License, or (at your option)
# any later version.
#
# This program is distributed in the hope that it will be useful, but WITHOUT
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
# FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for
# more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA.
#
"""Make programs out of your Python functions that can be run from the
command line by simply adding a decorator in front of the function. The
programs will have a commandline interface based on the optparse module,
and load data from and save data to files (HDF5 format).

The module name "frog" is meant to be a silly shortcut for
"function program".

Simple example:

> # file "my_module.py"
> from frog import Frog
> @Frog(inmap=dict(x='$@/dset'), preproc=dict(x=list_of(float)))
> def mean(x):
>   return sum(x)/len(x)

Now, you can create a small executable script with the following content:
> import sys, my_module
> sys.exit(my_module._mean())

The way the frog is configured in this example, it expects you to specify
a bunch of HDF5 data files, where each file has a dataset called "dset", and
the function will be called with the list [x1, x2, x3, ...]
(length == number of files). By default, the result of the function goes to
STDOUT (displayed on the screen). However, the behavior can be configured in
various ways and of course strongly depends on the user's requirements.

To do:
--> enable parallel execution if in independent execution mode
--> warn about usage with interactively defined functions? (no __name__)
--> be able to specify a fixed file, so instead of "$1/some/dataset", be able
    to specify "some/file.h5/some/dataset" (for input and output as well)
    setting default values in input mapping would then only be possible for
    non-strings (strings were already restricted before, could not start with
    "$", "%" or "#")
--> allow slices in mappings, like "$1:/dset" (all but the first file) or
    "$:4" (the first four arguments) or "$:" (all arguments, equivalent to
    "$@")
--> case dep+@: be able to restrict number of input/output arguments (min/max)?
--> understand combined filename/dataset paths, including patterns in both
    parts of the path (feature which is already provided through h5obj.tools)
--> in addition, access dataset attributes, e.g. inmap=dict(a='$0/dset/attr')
--> enable frog configuration options --inmap and --outmap? (update dict)
--> enable frog configuration options --preproc and --postproc? (update dict)
--> even if no arguments are expected at all, make sure the function is still
    executed
--> reroute STDOUT and STDERR to file? could be important for parallel
    execution. DENIED!
--> access metadata in output mapping, e.g. DATE, TIMINGS, DATE_BEGIN, DATE_END
--> if default value is True (or bool in general), behave accordingly
--> convert Frog class to a function (class not really neccessary)
--> make timings available in output mapping. Difficult, because right now,
    output mapping is a tuple and not a dict. One would have to change it to a
    dict. Default would be something like dict(0='#0/0', 1='#0/1', 2='#0/2'),
    but it then could also contain things like DATE='%0/current_date' etc.
    A lot would have to be changed, would require a version 0.3...
--> enable timings in milliseconds, reformat, make a new _nicetime function
"""
__created__  = '2013-06-28'
__modified__ = '2013-08-07'
__version__  = '0.2'
import inspect, itertools, os, sys, time
import dummy, h5obj, progress
from columnize import columnize
#from functools import wraps ## use this? probably not, as our "wrapper" is a
                             ## whole other function with another interface

try: import optparse2 as optparse
except ImportError: import optparse




class Frog(object):
  def __init__(self, inmap=None, outmap=None, preproc=None, postproc=None,
               opttypes=None, optdoc=None, shortopts=None, longopts=None,
               prolog='', epilog='', usage='', version='', wrapname='',
               overwrite=None, bar=False, stdin_sep=None, stdout_sep=None,
               first=None, last=None):
    """Initialize and configure frog decorator."""

    ### do this later?
    if prolog and prolog.strip()[-1] != '\n': prolog += '\n'
    try:
        prog = sys.argv[0].rsplit('/', 1)[1]
    except:
        prog = ''
    if isinstance(outmap, basestring): outmap = [outmap]

    # store configuration
    self.inmap       = inmap or dict()
    self.outmap      = tuple(outmap) if outmap is not None else [] # not (,)?
    self.preproc     = preproc or dict()
    self.postproc    = postproc or dummy.function1
    self.opttypes    = opttypes or dict()
    self.optdoc      = optdoc or dict() # documentation for keyword arguments
    self.shortopts   = shortopts or dict() # short option name, e.g. "-v"
    self.longopts    = longopts or dict() # long option name, e.g. "--verbose"
    self.prolog      = prolog  # text shown in help in front of documentation
    self.epilog      = epilog  # text shown in help after option list
    self.usage       = usage   # usage, e.g. prog [filenames ...] [-s]
    self.version     = version or ' '
    self.wrapname    = wrapname  # choose custom name for the wrapper function
    self.bar         = bar
    self.prog        = prog      # name of the executable script
    self.stdin_sep   = stdin_sep  or ' ' # separator between columns in STDIN
    self.stdout_sep  = stdout_sep or ' ' # separator between columns in STDOUT
    self._stdin_eof  = False # flag for STDIN received EOF
    self.parallel    = False
    self.overwrite   = overwrite
    self.first       = first or dummy.function
    self.last        = last or dummy.function

  def __call__(self, func):
    """When the decorator is applied to the user's function, this method is
    called with the function object. It will not touch the function object
    itself and return it in the end. But an additional wrapper function will
    be created in the same module which has the same name as the user's
    function but with a leading underscore. Further more, the wrapper
    function will have the attribute "__frog__" which is set to True. In this
    way, it may be checked which of the functions defined in a module are
    frog wrappers. The executable script is supposed to call that wrapper
    function, i.e. using "sys.exit(my_module._my_wrapper())"."""

    # inspect function
    fmodule  = inspect.getmodule(func)
    fname    = func.__name__
    fdoc     = func.__doc__ or ''
    mname    = fmodule.__name__
    fdoc = '\n'.join([s.strip() for s in fdoc.split('\n')])
    #fversion = getattr(self, 'version') \
               #or time.ctime(os.path.getmtime(fmodule.__file__))
    self.fargnames, self.fvarargsname, self.fvarkwname, defaults \
    = inspect.getargspec(func)

    # make defaults dictionary
    defaults = list(defaults) if defaults is not None else []
    self.fdefaults = {}
    for fargname, default in zip(self.fargnames[::-1], defaults[::-1]):
      self.fdefaults[fargname] = default
    if self.fvarargsname: self.fdefaults[self.fvarargsname] = []
    if self.fvarkwname: self.fdefaults[self.fvarkwname] = {}

    # determine which arguments are required, because they don't have a
    # default value
    self.frequired = []
    for fargname in self.fargnames:
      if fargname not in self.fdefaults:
        self.frequired.append(fargname)

    # determine name of the wrapper function
    wrapname = self.wrapname or '_'+fname

    #@wraps(func) ## use this? probably not, as our "wrapper" is a whole
                  ## other function with another interface
    class Wrapper(object):
      __frog__ = True # so functions can easily be identified as frogs

      def __call__(wself):
        """The executable script associated with the function is supposed to
        call this function. It is not expecting any arguments (the command
        line arguments will be obtained later) and is returning the exit
        status."""

        # first of all, initialize time measurement
        self.time0 = time.time()
        self.timings = dict(load=[], preproc=[], call=[], postproc=[], save=[],
                            loop=[])

        # determine input argument mapping
        # automatically add required arguments to the mapping
        for ind, reqarg in enumerate(self.frequired):
          if reqarg not in self.inmap:
            mapping = '$%i' % ind
            if self.any_startswith(self.inmap.values(), mapping):
              self.raise_reqarg_not_in_inmap(reqarg)
            self.inmap[reqarg] = mapping

        # automatically add varargs and varkw to mapping
        if self.fvarargsname and self.fvarargsname not in self.inmap \
        and not self.fargnames \
        and not self.any_startswith(self.inmap.values(), '$@'):
          self.inmap[self.fvarargsname] = '$@'
        if self.fvarkwname and self.fvarkwname not in self.inmap \
        and not self.fargnames and not self.fvarargsname \
        and not self.any_startswith(self.inmap.values(), '$0'):
          self.inmap[self.fvarkwname] = '$0'

        # determine execution mode
        # (independent or not, or in other words, sequential or all-at-once)
        indep = self.get_indep(self.inmap, self.outmap)
        ### MAYBE DETERMINE indep AFTER tninargs AND tnoutargs (less tedious)

        # get theoretical number of input and output arguments
        # (either a fixed non-negative number or 'inf')
        tninargs  = self.get_tninargs(self.inmap, indep)
        tnoutargs = self.get_tnoutargs(self.outmap, tninargs, indep)

        # generate suitable usage message
        if not self.usage:
          self.usage = self.auto_usage(tninargs, tnoutargs, indep,
                                       self.inmap, self.outmap)

        # define command line interface
        description = self.prolog+'\n'+fdoc if self.prolog else fdoc
        op = optparse.OptionParser(usage=self.usage, epilog=self.epilog,
                                   description=description,
                                   prog=self.prog, version=self.version)

        # define general frog options
        og = optparse.OptionGroup(op, 'Frog configuration')
        og.add_option('-I', '--info', default=False, action='store_true',
                      help='show frog information and exit')
        og.add_option('--info-fdefaults', default=False, action='store_true',
                      help='show function default arguments and exit')
        og.add_option('--info-preproc', default=False, action='store_true',
                      help='show preprocessors and exit')
        og.add_option('--info-postproc', default=False, action='store_true',
                      help='show postprocessors and exit')
        og.add_option('--info-inmap', default=False, action='store_true',
                      help='show input mapping and exit')
        og.add_option('--info-predata', default=False, action='store_true',
                      help='show predata and exit')
        og.add_option('--info-indata', default=False, action='store_true',
                      help='show indata and exit')
        og.add_option('--info-inargs', default=False, action='store_true',
                      help='show inargs and exit')
        og.add_option('--info-inkwargs', default=False, action='store_true',
                      help='show inkwargs and exit')
        og.add_option('--info-outdata', default=False, action='store_true',
                      help='show outdata and exit')
        og.add_option('--info-postdata', default=False, action='store_true',
                      help='show postdata and exit')
        og.add_option('--info-outmap', default=False, action='store_true',
                      help='show output mapping and exit')
        og.add_option('-O', '--overwrite', default=False,
                      action='store_true',
                      help='overwrite existing datasets')
        og.add_option('--no-overwrite', default=False, action='store_true',
                      help='do not overwrite existing datasets')
        og.add_option('-B', '--bar', default=False, action='store_true',
                      help='show progress bar (only in sequential or '+\
                           'parallel execution mode)')
        og.add_option('--no-bar', default=False, action='store_true',
                      help='do not show progress bar')
        og.add_option('-F', '--cmdfile', default=None, type=str,
                      help='save command line to the given text file')
        og.add_option('-C', '--cmd', default=False, action='store_true',
                      help='save command line to the text file "X.cmd", '+\
                           'where X is the name of the program')
        og.add_option('-E', '--must-exist', dest='must_exist', default=False,
                      action='store_true',
                      help='output files must exist, skip otherwise')
        og.add_option('-T', '--timings', default=False, action='store_true',
                      help='show timings')
        #og.add_option('-P', '--parallel', default=False, action='store_true',
                      #help='run parallel threads')
        #og.add_option('--no-parallel', default=False, action='store_true',
                      #help='do not run parallel threads')
        #og.add_option('-N', '--num_threads', default=0, action='store_true',
                      #help='number of parallel threads. If smaller than '+\
                           #'one, detect and use number of CPU cores')
        op.add_option_group(og)

        # turn function arguments with default values into options
        self.optnames = [] ### do I need this list? could be handy...
        for argname, default in self.fdefaults.iteritems():
          if argname in self.inmap \
          and isinstance(self.inmap[argname], basestring) \
          and self.startswith_one_of(self.inmap[argname], '$%#'):
            continue

          shortopt = '-'+str(self.shortopts.get(argname, argname[0]))
          if len(shortopt[1:]) != 1: self.error_shortopt(shortopt)
          longopt  = '--'+str(self.longopts.get(argname, argname))
          defaulttype = type(default) if default is not None else str
          opttype = self.opttypes.get(argname, defaulttype)
          if opttype in (list, tuple, dict): opttype = str
          opttypename = getattr(opttype, '__name__')
          if opttype is bool:
            action = 'store_false' if default else 'store_true'
            opttype = None
          else:
            action = None
          opthelp = self.optdoc.get(argname,
                                    'keyword argument "%s", type %s' \
                                    % (argname, opttypename))
          op.add_option(shortopt, longopt, type=opttype, default=default,
                        action=action, help=opthelp, dest=argname)

          self.optnames.append(argname) ### do I need this list?

        # parse command line
        self.opts, args = op.parse_args()

        # update frog configuration
        if self.opts.overwrite:    self.overwrite = True
        if self.opts.no_overwrite: self.overwrite = False
        if self.opts.bar:    self.bar = True
        if self.opts.no_bar: self.bar = False
        #if self.opts.parallel:    self.parallel = True
        #if self.opts.no_parallel: self.parallel = False

        # show certain information about the frog and exit
        if self.opts.info_fdefaults:
          return self.display_keywords(self.fdefaults)
        if self.opts.info_preproc:
          return self.display_keywords(self.preproc)
        if self.opts.info_postproc:
          return self.display_object(self.postproc)
        if self.opts.info_inmap:
          return self.display_keywords(self.inmap)
        if self.opts.info_outmap and self.outmap:
          return self.display_keywords(self.outmap)

        # determine execution mode ("once", "para", or "seq")
        # (all-at-once, parallel, or sequential)
        exec_mode = self.get_exec_mode(tninargs, tnoutargs, indep,
                                       self.parallel)

        # show frog information and exit
        if self.opts.info:
          print '%s.%s' % (mname, wrapname),
          print '%s.%s' % (mname, fname),
          #print '%s>%s' % (self.informat, self.outformat),
          print '%s>%s' % (tninargs, tnoutargs),
          print 'para' if self.parallel \
                       else ('indep' if indep else 'dep'),
          print exec_mode
          return 0

        # divide argument list (input/output files)
        inargs, outargs = self.divide_args(args, tninargs, tnoutargs, indep)

        # skip if output files do not exist
        if self.opts.must_exist:
          for mapping in self.outmap:
            if mapping.startswith('%') and '/' in mapping:
              argind = self.get_argind(mapping, symbol='%')
              if argind is None: continue # support this as well
              filename = outargs[argind]
              if not os.path.isfile(filename):
                return 0

        self.timings['prepare'] = time.time()-self.time0

        # user-defined actions to do first (before entering execution)
        timestep = time.time()
        self.first()
        self.timings['first'] = time.time()-timestep

        # execute
        if exec_mode == 'once':
          ex = self.exec_once(inargs, outargs, self.opts, func)
        elif exec_mode == 'seq':
          ex = self.exec_seq(inargs, outargs, self.opts, func, indep,
                             tninargs, tnoutargs)
        elif exec_mode == 'para':
          raise NotImplementedError, 'parallel execution not implemented'
        else:
          self.raise_exec_mode()

        # user-defined actions to do last (after execution)
        timestep = time.time()
        self.last()
        self.timings['last'] = time.time()-timestep

        # write command line to log file
        if self.opts.cmd or self.opts.cmdfile:
            logfile = self.opts.cmdfile or self.prog+'.cmd'
            with open(logfile, 'w') as f:
                f.write(self.prog+' '+' '.join(sys.argv[1:])+'\n')

        # end time measurements
        self.timings['total'] = time.time()-self.time0
        if self.opts.timings:
            self.print_timings()

        return ex

      def __repr__(wself):
        return '<frog wrapper for %s.%s>' % (fmodule.__name__, fname)

    # put frog into module
    wrapper = Wrapper()
    wrapper.__doc__ = self.prolog+'\n'+(func.__doc__ or '')
    wrapper.__name__ = wrapname
    if hasattr(fmodule, wrapname):
      if self.wrapname: self.raise_wrapname_exists(wrapname)
      num = 2
      while hasattr(fmodule, wrapname+str(num)): num += 1
      wrapname += str(num)
    setattr(fmodule, wrapname, wrapper)
    return func # return original function, untouched


  def print_timings(self):
        print 'total: %s | prepare: %s | first: %s | last: %s' \
              % (_nicetime(self.timings['total']),
                 _nicetime(self.timings['prepare']),
                 _nicetime(self.timings['first']),
                 _nicetime(self.timings['last']))
        print '          mean      min       max'
        for field in ('loop', 'load', 'preproc', 'call', 'postproc', 'save'):
            data = self.timings[field]
            mean = sum(data)/len(data)
            dmin = min(data)
            dmax = max(data)
            print '%-8s  %-8s  %-8s  %-8s' \
                    % (field, _nicetime(mean), _nicetime(dmin),
                            _nicetime(dmax))



  def exec_once(self, inargs, outargs, opts, func):
    """Load and save all data, function has access to all the data at
    once."""
    time0 = time.time()

    # load data
    timestep = time.time()
    predata = self.fdefaults.copy()
    optvalues = dict((optname, getattr(opts, optname)) \
                     for optname in self.optnames)
    predata.update(optvalues)
    loaded = self.load_indata_once(inargs, self.inmap)
    predata.update(loaded)
    if self.opts.info_predata: return self.display_keywords(predata)
    self.timings['load'].append(time.time()-timestep)

    # apply preprocessor
    timestep = time.time()
    indata = self.apply_preproc(predata)
    if self.opts.info_indata: return self.display_keywords(indata)
    self.timings['preproc'].append(time.time()-timestep)

    # prepare data for function call
    finargs, finkwargs = self.split_indata(indata)
    if self.opts.info_inkwargs: return self.display_keywords(finkwargs)
    if self.opts.info_inargs: return self.display_list(finargs)

    # call function
    timestep = time.time()
    outdata = func(*finargs, **finkwargs)
    if self.opts.info_outdata: return self.display_object(outdata)
    self.timings['call'].append(time.time()-timestep)

    # apply postprocessor
    timestep = time.time()
    postdata = self.apply_postproc(outdata)
    if self.opts.info_postdata: return self.display_object(postdata)
    self.timings['postproc'].append(time.time()-timestep)

    self.outmap = self.auto_outmap(self.outmap, postdata)
    if self.opts.info_outmap: return self.display_list(self.outmap)

    # save data
    timestep = time.time()
    ex = self.save_outdata_once(outargs, self.outmap, postdata, inargs)
    self.timings['save'].append(time.time()-timestep)

    self.timings['loop'].append(time.time()-time0)
    return ex


  def exec_seq(self, inargs, outargs, opts, func, indep,
               tninargs, tnoutargs):
    """Load and save data one by one, function works on each chunk (argument
    or argument pair or file or file pair or STDIN/STDOUT line separately."""
    self._stdin_eof = False # initialize flag that EOF has been received

    # calculate number of loops
    nloop = 0
    if tninargs != 'inf': nloop = tninargs
    if tnoutargs != 'inf' and tnoutargs > tninargs: nloop = tnoutargs
    if not tninargs and not tnoutargs: nloop = 1
    if len(inargs) > nloop: nloop = len(inargs)
    if len(outargs) > nloop: nloop = len(outargs)
    eternal = self.any_startswith(self.inmap.values(), '#@') \
              or indep and self.any_startswith(self.inmap.values(), '#')

    with progress.Bar(nloop, verbose=self.bar) as bar:
      i = 0
      while i < nloop or eternal:
        time0 = time.time()

        inarg  = inargs[i]  if i < len(inargs)  else None
        outarg = outargs[i] if i < len(outargs) else None

        # load data
        timestep = time.time()
        predata = self.fdefaults.copy()
        optvalues = dict((optname, getattr(opts, optname)) \
                         for optname in self.optnames)
        predata.update(optvalues)
        loaded = self.load_indata_seq(inarg, self.inmap)
        if self._stdin_eof: break
        predata.update(loaded)
        if self.opts.info_predata: return self.display_keywords(predata)
        self.timings['load'].append(time.time()-timestep)

        # apply preprocessor
        timestep = time.time()
        indata = self.apply_preproc(predata)
        if self.opts.info_indata: return self.display_keywords(indata)
        self.timings['preproc'].append(time.time()-timestep)

        # prepare data for function call
        finargs, finkwargs = self.split_indata(indata)
        if self.opts.info_inkwargs: return self.display_keywords(finkwargs)
        if self.opts.info_inargs: return self.display_list(finargs)

        # call function
        timestep = time.time()
        outdata = func(*finargs, **finkwargs)
        if self.opts.info_outdata: return self.display_object(outdata)
        self.timings['call'].append(time.time()-timestep)

        # apply postprocessor
        timestep = time.time()
        postdata = self.apply_postproc(outdata)
        if self.opts.info_postdata: return self.display_object(postdata)
        self.timings['postproc'].append(time.time()-timestep)

        self.outmap = self.auto_outmap(self.outmap, postdata)
        if self.opts.info_outmap: return self.display_list(self.outmap)

        # save data
        timestep = time.time()
        self.save_outdata_seq(outarg, self.outmap, postdata, inarg)
        self.timings['save'].append(time.time()-timestep)

        bar.step()
        i += 1

        self.timings['loop'].append(time.time()-time0)

    # return positive exit status to the executable script
    return 0


  def auto_usage(self, tninargs, tnoutargs, indep, inmap, outmap):
        """Generate a suitable usage string based on frog configuration."""
        # input part
        if indep:
            if self.any_startswith(inmap.values(), '$0/'):
                if self.any_startswith(outmap, '$0/'):
                    inpart = '[FILE_1 [FILE_2 [...]]]'
                else:
                    inpart = '[INPUT_FILE_1 [INPUT_FILE_2 [...]]]'
            elif '$0' in inmap.values():
                for argname, mapping in inmap.iteritems():
                    if isinstance(mapping, basestring) and mapping == '$0':
                        inpart = '[%s_1 [%s_2 [...]]]' % ((argname.upper(),)*2)
                        break
                    else:
                        inpart = ''
                else:
                    inpart = ''
            else:
                inpart = ''
        else:
            if self.any_startswith(inmap.values(), '$@/'):
                if self.any_startswith(outmap, '$@/'):
                    inpart = '[FILE_1 [FILE_2 [...]]]'
                else:
                    inpart = '[INPUT_FILE_1 [INPUT_FILE_2 [...]]]'
            elif '$@' in inmap.values():
                for argname, mapping in inmap.iteritems():
                    if isinstance(mapping, basestring) and mapping == '$@':
                        inpart = '[%s_1 [%s_2 [...]]]' % ((argname.upper(),)*2)
                        break
                else:
                    inpart = ''
            else:
                mappings = {}
                for argname, mapping in inmap.iteritems():
                    if isinstance(mapping, basestring) \
                            and mapping.startswith('$'):
                        mappings[mapping] = argname
                keys = mappings.keys()
                keys.sort()
                inpartlist = []
                for key in keys:
                    argname, mapping = mappings[key], key
                    if '/' in mapping:
                        index = mapping.index('/')
                        if self.any_startswith(outmap, mapping[:(index+1)]):
                            inpartlist.append('FILE')
                        else:
                            inpartlist.append('INPUT_FILE')
                    else:
                        inpartlist.append(argname.upper())
                inpart = ' '.join(inpartlist)

        # output part
        if indep:
            if self.any_startswith(outmap, '%0/'):
                outpart = '[OUTPUT_FILE_1 [OUTPUT_FILE_2 [...]]]'
            else:
                outpart = ''
        else:
            ### to do: support $@ and %@, like in input part above
            indices = []
            for mapping in outmap:
                if isinstance(mapping, basestring) \
                        and mapping.startswith('%') and '/' in mapping:
                    indices.append(self.get_argind(mapping))
            if len(indices) > 1:
                outpart = ' '.join(['OUTPUT_FILE_%i' % i \
                                    for i in xrange(len(indices))])
            elif len(indices) == 1:
                outpart = 'OUTPUT_FILE'
            else:
                outpart = ''

        # put it together
        if inpart and outpart:
            inpart += ' '
        return '%prog [options] '+inpart+outpart


  @staticmethod
  def auto_outmap(outmap, outdata):
    """Automatically fill output mapping with standard mappings if it is
    still empty."""
    if outdata is None: return outmap
    if not outmap:
      if type(outdata) is tuple:
        return tuple(['#0/%i' % index for index in xrange(len(outdata))])
      else:
        return ('#0',)
    return outmap


  def get_tninargs(self, inmap, indep):
    if self.any_startswith(inmap.values(), '$@'): return 'inf'
    if not self.any_startswith(inmap.values(), '$'): return 0
    if indep: return 'inf'
    maxindex = -1
    for mapping in inmap.values():
      index = self.get_argind(mapping, symbol='$')
      if index is not None and index > maxindex: maxindex = index
    return maxindex+1


  def get_tnoutargs(self, outmap, tninargs, indep):
    if self.any_startswith(outmap, '%@/'): return 'inf'
    elif self.any_startswith(outmap, '$@/'): return 0 #'same'
    #if indep: return 'inf' ## ???
    maxindex = -1
    for mapping in outmap:
      index = self.get_argind(mapping, symbol='%')
      if index is not None and index > maxindex: maxindex = index
    return maxindex+1


  def get_indep(self, inmap, outmap):
    """Determine independent mode, i.e. find out if function only depends on
    maximal one input and maximal one output argument, so that it can be
    applied independently (sequential or parallel) on all the arguments or
    data files."""
    # as soon as a $1 (or higher) is found in inmap, or a $1 or %1 is found
    # in outmap, return False
    for mapping in inmap.values()+list(outmap):
      if not isinstance(mapping, basestring): continue
      if mapping.startswith('$@'): return False
      if mapping.startswith('%@'): return False
      if mapping.startswith('#@'): return False
      if mapping.startswith('%') and not '/' in mapping: continue
      if mapping.startswith('$') or mapping.startswith('%'):
        slashpos = mapping.find('/')
        slashpos = None if slashpos == -1 else slashpos
        try: value = int(mapping[1:slashpos])
        except: continue
        if value and value > 0: return False
    return True


  def get_exec_mode(self, tninargs, tnoutargs, indep, parallel):
    """Determine execution mode (sequential, parallel or all at once).
    Returns "para", "seq" or "once"."""
    if tnoutargs in (tninargs, 0) or tninargs == 0:
      if indep:
        return 'para' if parallel else 'seq'
      else:
        if parallel: self.raise_parallel()
        return 'once'
    else:
      if indep: self.raise_indep()
      return 'once'


  def divide_args(self, args, tninargs, tnoutargs, indep):
    """Divide arguments into two parts (input and output). If an error is
    found, return the error code. Otherwise, return a tuple of two lists."""
    nargs = len(args)
    if tninargs == 'inf':
      if tnoutargs == 'inf':
        if not self.is_even(nargs): self.error_arg_pairs()
        mark = nargs/2
        return args[:mark], args[mark:]
      else:
        if nargs < tnoutargs: return self.error_nargs_min(tnoutargs)
        mark = nargs-tnoutargs
        return args[:mark], args[mark:]
    else:
      if tnoutargs == 'inf':
        if nargs < tninargs: return self.error_nargs_min(tninargs)
        mark = tninargs
        return args[:mark], args[mark:]
      else:
        if not indep and nargs != tninargs+tnoutargs:
          self.error_nargs(tninargs+tnoutargs)
        mark = tninargs
        return args[:mark], args[mark:]


  @staticmethod
  def get_argind(mapping, symbol='$'):
    """Extract the argument index from a mapping, i.e. the number in "$1" or
    "$2/any_dataset". Return None if mapping is not string, or doesn't start
    with "$", or starts with "$@". Instead of "$", another symbol can be
    chosen."""
    if isinstance(mapping, basestring) and mapping.startswith(symbol):
      slashpos = mapping.find('/')
      slashpos = None if slashpos == -1 else slashpos
      try: value = int(mapping[1:slashpos])
      except: return None
      return value
    return None


  def display_keywords(self, dictionary):
    print repr(dictionary)
    #keys = dictionary.keys()
    #keys.sort()
    #for key in keys:
      #value = dictionary[key]
      #print '%s=%s (%s)' % (key, repr(value), type(value).__name__)


  def display_list(self, iterable):
    if iterable:
      #print ', '.join([repr(i) for i in iterable])
      print repr(iterable)


  def display_object(self, obj):
    print repr(obj)


  def split_indata(self, indata):
    """Convert input data (already preprocessed) into a variable list of
    arguments (inargs) and a dictionary of keyword arguments (inkwargs),
    ready to be passed to the function."""
    inargs = []
    for argname in self.fargnames:
      inargs.append(indata.pop(argname))
    inargs += indata.pop(self.fvarargsname, [])

    inkwargs = indata.pop(self.fvarkwname, {})
    for argname in self.fargnames:
      if argname in inkwargs: del inkwargs[argname]
    inkwargs.update(indata) # put all the remaining arguments in there

    return inargs, inkwargs


  def apply_preproc(self, indata):
    """Apply preprocessors to input data."""
    if self.preproc is None: return indata
    if not isinstance(self.preproc, dict): self.raise_preproc() 
    for name, prep in self.preproc.iteritems():
      if prep is not None and name in indata: # if None, del indata[name]?
        indata[name] = prep(indata[name])
    return indata


  def apply_postproc(self, outdata):
    """Apply postprocessors to output data."""
    if hasattr(self.postproc, '__iter__') \
    and not type(self.postproc) is type:
      # if outdata is scalar, also postprocessor must be scalar
      if not hasattr(outdata, '__iter__'): self.raise_postproc_iter()
      self.postproc = list(self.postproc)
      while self.postproc and self.postproc[-1] is None:
        del self.postproc[-1]
      if len(self.postproc) > len(outdata):
        self.raise_postproc_len(len(outdata))
      while len(self.postproc) < len(outdata):
        self.postproc.append(None)
      for i  in xrange(len(self.postproc)):
        if self.postproc[i] is None:
          self.postproc[i] = dummy.function1
      return tuple([postp(outdat) \
                    for postp, outdat in zip(self.postproc, outdata)])
    else:
      return self.postproc(outdata)


  def save_outdata_once(self, outargs, outmap, outdata, inargs):
    """Save all output data at once (execution mode "all-at-once")."""

    # initialize STDOUT datastructure (mapping rowindex-->rowdata or just
    # data. rowdata can in turn be either a mapping colindex-->celldata or
    # just rowdata)
    stdout_data = None

    if type(outdata) is tuple:
      if len(outmap) > len(outdata): self.raise_outmap_len(len(outdata))
    else:
      if len(outmap) > 1: self.raise_outmap_len(1)
      outdata = (outdata,)
    for data, mapping in zip(outdata, outmap):
      if mapping is None:
        continue

      elif isinstance(mapping, basestring) and mapping.startswith('#'):
        # send data to STDOUT, maybe choose row, maybe choose column
        if mapping.count('/') > 1: self.raise_outmap(mapping)
        if mapping.startswith('#@'):
          # set whole STDOUT or whole columns at once
          if not hasattr(data, '__iter__'):
            self.raise_outdata_iterable(mapping)
          if '/' in mapping:
            # set whole column with data
            if stdout_data is None: stdout_data = {}
            colindex = int(mapping.split('/')[1])
            if colindex in stdout_data: self.raise_stdout_structure()
            for rowindex, item in enumerate(data):
              if not rowindex in stdout_data: stdout_data[rowindex] = {}
              if type(stdout_data[rowindex]) is not dict:
                self.raise_stdout_structure()
              stdout_data[rowindex][colindex] = data

          else:
            # set whole STDOUT with data
            #if type(stdout_data) is dict: self.raise_stdout_structure()
            if stdout_data is None: stdout_data = {}
            for rowindex, rowdata in enumerate(data):
              stdout_data[rowindex] = rowdata

        else:
          # set a whole row or a single cell
          if stdout_data is None: stdout_data = {}
          if type(stdout_data) is not dict: self.raise_stdout_structure()
          rowindex = self.get_argind(mapping, symbol='#')
          if rowindex is None: self.raise_argind(mapping)
          if '/' in mapping:
            # set a specific cell
            if rowindex not in stdout_data: stdout_data[rowindex] = {}
            if type(stdout_data[rowindex]) is not dict:
              self.raise_stdout_structure()
            colindex = int(mapping.split('/')[1])
            stdout_data[rowindex][colindex] = data

          else:
            # set a whole row
            stdout_data[rowindex] = data

      elif isinstance(mapping, basestring) and mapping.startswith('$'):

        # save data back to input file
        if not '/' in mapping: self.raise_outmap(mapping)
        dsetname = '/'.join(mapping.split('/')[1:])
        if mapping.startswith('$@/'):
          # distribute the (iterable) object to all files
          # must have the right length
          if len(inargs) != len(data): self.raise_outdata_len(len(inargs))
          for fileindex, filename in enumerate(inargs):
            self.save_dset(filename, dsetname, data[fileindex],
                           self.overwrite)

        else:
          # save this object back to one specific input file
          argind = self.get_argind(mapping, symbol='$')
          if argind is None: self.raise_argind(mapping)
          if argind > len(inargs): self.raise_argind(mapping)
          filename = inargs[argind]
          self.save_dset(filename, dsetname, data, self.overwrite)

      elif isinstance(mapping, basestring) and mapping.startswith('%'):
        # save data to dedicated output file
        if not '/' in mapping: self.raise_outmap(mapping)
        dsetname = '/'.join(mapping.split('/')[1:])
        if mapping.startswith('%@/'):
          # distribute the (iterable) object to all files
          # must have the right length
          if len(outargs) != len(data): self.raise_outdata_len(len(outargs))
          for fileindex, filename in enumerate(outargs):
            self.save_dset(filename, dsetname, data[fileindex],
                           self.overwrite)

        else:
          # save this object to one specific output file
          argind = self.get_argind(mapping, symbol='%')
          if argind is None: self.raise_argind(mapping)
          if argind > len(outargs): self.raise_argind(mapping)
          filename = outargs[argind]
          self.save_dset(filename, dsetname, data, self.overwrite)

      else:
        self.raise_outmap(mapping)

    # write to STDOUT
    if stdout_data is None: return
    lines = []
    if type(stdout_data) is dict:
      nlines = max(stdout_data.keys())+1
      lines = ['']*nlines
      for rowindex, row in stdout_data.iteritems():
        if type(row) is dict:
          rowlen = max(row.keys())+1 if row else 0
          rowlist = ['']*rowlen
          for colindex, cell in row.iteritems():
            rowlist[colindex] = str(cell)
          line = self.stdout_sep.join(rowlist)
        else:
          line = str(row)
        lines[rowindex] = line
    else:
      lines = str(stdout_data)
    for line in lines:
      print line


  def save_outdata_seq(self, outarg, outmap, outdata, inarg):
    """Save a single chunk of output data (belonging to at most one output
    file or one line of standard output) (execution mode "sequential" or
    "parallel")."""

    # initialize STDOUT datastructure (mapping colindex-->celldata or just
    # rowdata)
    stdout_data = None

    if type(outdata) is tuple:
      if len(outmap) > len(outdata): self.raise_outmap_len(len(outdata))
    else:
      if len(outmap) > 1: self.raise_outmap_len(1)
      outdata = (outdata,)
    for data, mapping in zip(outdata, outmap):
      if mapping is None:
        continue

      elif isinstance(mapping, basestring) and mapping.startswith('#'):
        # send data to STDOUT, maybe choose column
        if mapping.count('/') > 1: self.raise_outmap(mapping)
        if mapping.startswith('#@'):
          self.raise_outmap(mapping)
        else:
          # set a whole row or a single cell
          if stdout_data is None: stdout_data = {}
          if type(stdout_data) is not dict: self.raise_stdout_structure()
          rowindex = self.get_argind(mapping, symbol='#')
          if rowindex is None or rowindex > 0: self.raise_argind(mapping)
          if '/' in mapping:
            # set a specific cell
            if rowindex not in stdout_data: stdout_data[rowindex] = {}
            if type(stdout_data[rowindex]) is not dict:
              self.raise_stdout_structure()
            colindex = int(mapping.split('/')[1])
            stdout_data[rowindex][colindex] = data

          else:
            # set the whole row
            stdout_data[rowindex] = data

      elif isinstance(mapping, basestring) and mapping.startswith('$'):
        # save data back to input file
        if not '/' in mapping: self.raise_outmap()
        dsetname = '/'.join(mapping.split('/')[1:])
        if mapping.startswith('$@/'):
          self.raise_outmap(mapping)
        else:
          # save this object back to one specific input file
          argind = self.get_argind(mapping, symbol='$')
          if argind is None or argind > 0: self.raise_argind(mapping)
          filename = inarg
          self.save_dset(filename, dsetname, data, self.overwrite)

      elif isinstance(mapping, basestring) and mapping.startswith('%'):
        # save data to dedicated output file
        if not '/' in mapping: self.raise_outmap(mapping)
        dsetname = '/'.join(mapping.split('/')[1:])
        if mapping.startswith('%@/'):
          self.raise_outmap(mapping)
        else:
          # save this object to one specific output file
          argind = self.get_argind(mapping, symbol='%')
          if argind is None or argind > 0: self.raise_argind(mapping)
          filename = outarg
          self.save_dset(filename, dsetname, data, self.overwrite)

      else:
        self.raise_outmap(mapping)

    # write to STDOUT
    if stdout_data is None: return
    elif type(stdout_data) is dict:
      rowlen = max(stdout_data.keys())+1 if stdout_data else 0
      rowlist = ['']*rowlen
      for colindex, cell in stdout_data.iteritems():
        rowlist[colindex] = str(cell)
      line = self.stdout_sep.join(rowlist)
    else:
      line = str(stdout_data)
    if line: print line


  def save_dset(self, filename, dsetname, data, overwrite=None, mode='a'):
    """Save dataset to file. Overwrite if self.overwrite is True, never
    overwrite if self.overwrite is False, and if it is None, prompt
    the user to decide."""
    if os.path.exists(filename):
      with h5obj.File(filename, 'r') as f:
        found = dsetname in f
    else:
      found = False
    if found and overwrite is False:
      self.error_dset_omit(dsetname, filename)
    if found and overwrite is None:
      message = '%s: overwrite "%s" [yes|no|all]? ' \
                % (self.prog, filename+'/'+dsetname)
      answer = raw_input(message).lower()
      if not answer or 'no'.startswith(answer): return
      elif 'all'.startswith(answer): self.overwrite = True
      elif 'yes'.startswith(answer): pass
      else: return
    with h5obj.File(filename, mode) as f:
      if found: del f[dsetname]
      f[dsetname] = data


  def load_indata_once(self, inargs, inmap):
    """Load all input data at once (execution mode "all-at-once")."""

    # DEFINITION: #0 means "row 1 from stdin", #@ means "all rows from stdin"
    # multiple values from one row are referenced by something like "#0/0",
    # "#0/1", "#0/2"

    # here: load all STDIN at once! do it now!
    # if there are more rows than expected, fine, than just pick the ones
    # referenced (e.g. #0, #2 and #6)
    # if there are not enough rows, then error (e.g. #6 was specified, but
    # STDIN has less than 7 rows)

    if self.any_startswith(inmap.values(), '#'):
      stdin = sys.stdin.readlines()
      stdin_lines = stdin.split('\n') if stdin else []

    indata = {}
    for argname, mapping in inmap.iteritems():
      if isinstance(mapping, basestring) and mapping.startswith('#'):
        # from STDIN
        if mapping.count('/') > 1: self.raise_inmap(mapping)
        if '/' in mapping:
          if mapping.startswith == '#@/':
            # load a specific column
            data = []
            colindex = int(mapping.split('/')[1])
            for line in stdin_lines:
              values = line.split(self.stdin_sep)
              if colindex > len(values)-1: self.raise_stdin_structure()
              data.append(values[colindex].strip())
            indata[argname] = data
          else:
            # load a specific cell
            argind = self.get_argind(mapping, symbol='#')
            if argind is None: self.raise_argind(mapping)
            if argind > len(stdin_lines): self.error_stdin_len()
            values = stdin_lines[argind].split(self.stdin_sep)
            colindex = int(mapping.split('/')[1])
            if colindex > len(values)-1: self.raise_stdin_structure()
            indata[argname] = values[colindex].strip()
        else:
          if mapping == '#@':
            # load whole standard input
            indata[argname] = stdin
          else:
            # load a specific row
            argind = self.get_argind(mapping, symbol='#')
            if argind is None: self.raise_argind(mapping)
            if argind > len(stdin_lines): self.error_stdin_len()
            indata[argname] = stdin_lines[argind]

      elif isinstance(mapping, basestring) and mapping.startswith('$'):
        # from CL argument
        if '/' in mapping:
          # CL argument is filename, load data from file
          dsetname = '/'.join(mapping.split('/')[1:])
          if mapping.startswith('$@/'):
            # get dataset from all files
            indata[argname] = []
            for filename in inargs:
              with h5obj.File(filename, 'r') as f:
                found = dsetname in f
                if found: data = f[dsetname]
              if not found:
                if argname in self.fdefaults:
                  data = self.fdefaults[argname]
                else:
                  self.error_dset_not_found(dsetname, filename)
              indata[argname].append(data)
          else:
            # get dataset from one specific file
            argind = self.get_argind(mapping, symbol='$')
            if argind is None: self.raise_argind(mapping)
            filename = inargs[argind]
            if not os.path.exists(filename):
              self.error_file(filename)
            with h5obj.File(filename, 'r') as f:
              found = dsetname in f
              if found: data = f[dsetname]
            if not found:
              if argname in self.fdefaults:
                data = self.fdefaults[argname]
              else:
                self.error_dset_not_found(dsetname, filename)
            indata[argname] = data
        else:
          # CL argument contains data itself
          if mapping == '$@':
            indata[argname] = inargs
          else:
            argind = self.get_argind(mapping, symbol='$')
            indata[argname] = inargs[argind]

      elif isinstance(mapping, basestring) and mapping.startswith('%'):
        self.raise_percent_in_inmap(mapping)

      else:
        # set default value for this argument, make it an option
        ### really neccessary to add it to options here? I don't think so
        ### check inmap earlier, so that an option is created
        #self.fdefaults[argname] = mapping
        #if argname in self.frequired:
          #del self.frequired.index(argname)
        indata[argname] = mapping

    return indata


  def load_indata_seq(self, inarg, inmap):
    """Load only one chunk of data (belonging to one command line argument,
    one input file, or one line of standard input) (execution mode
    "sequential" or "parallel")."""

    if self.any_startswith(inmap.values(), '#'):
      stdin_line = self.read_stdin_line()
      if self._stdin_eof: return {} # leave early, cancel function call

    indata = {}
    for argname, mapping in inmap.iteritems():
      if isinstance(mapping, basestring) and mapping.startswith('#'):
        # from STDIN
        if mapping == '#@':
          self.raise_inmap(mapping)
        if mapping.count('/') > 1: self.raise_inmap(mapping)
        argind = self.get_argind(mapping, symbol='#')
        if argind is None or argind > 0: self.raise_argind(mapping)
        if '/' in mapping:
          # load specific cell
          values = stdin_line.split(self.stdin_sep)
          colindex = int(mapping.split('/')[1])
          if colindex > len(values)-1: self.raise_stdin_structure()
          indata[argname] = values[colindex].strip()
        else:
          # load whole row
          indata[argname] = stdin_line.strip()
      elif isinstance(mapping, basestring) and mapping.startswith('$'):
        # from CL argument
        if '/' in mapping:
          # CL argument is filename, load data from file
          dsetname = '/'.join(mapping.split('/')[1:])
          if mapping.startswith('$@/'):
            self.raise_inmap(mapping)
          else:
            # get dataset from one specific file
            argind = self.get_argind(mapping, symbol='$')
            if argind is None or argind > 0: self.raise_argind(mapping)
            filename = inarg
            if not os.path.exists(filename):
              self.error_file(filename)
            with h5obj.File(filename, 'r') as f:
              found = dsetname in f
              if found: data = f[dsetname]
            if not found:
              if argname in self.fdefaults:
                data = self.fdefaults[argname]
              else:
                self.error_dset_not_found(dsetname, filename)
            indata[argname] = data
        else:
          # CL argument contains data itself
          if mapping == '$@':
            self.raise_inmap(mapping)
          else:
            argind = self.get_argind(mapping, symbol='$')
            if argind > 0: self.raise_argind(mapping)
            indata[argname] = inarg

      elif isinstance(mapping, basestring) and mapping.startswith('%'):
        self.raise_percent_in_inmap(mapping)

      else:
        # set default value for this argument, make it an option
        ### really neccessary to add it to options here? I don't think so
        ### check inmap earlier, so that an option is created
        #self.fdefaults[argname] = mapping
        #if argname in self.frequired:
          #del self.frequired.index(argname)
        indata[argname] = mapping

    return indata


  def read_stdin_line(self):
    try: line = sys.stdin.readline()
    except KeyboardInterrupt: # "CTRL-c pressed"
      self._stdin_eof = True
      line = ','*(len(self.frequired)-1)
    if not line:
      self._stdin_eof = True # "CTRL-d pressed" / EOF
      line = ','*(len(self.frequired)-1)
    # strip just one '\n' at the end of the lines, not all
    if len(line) > 0 and line[-1] == '\n':
      line = line[:-1]
    return line


  @staticmethod
  def any_startswith(objects, string):
    """Return true if any of the given objects starts with the given
    string. Non-strings among the objects are ignored."""
    for obj in objects:
      if not isinstance(obj, basestring):
        continue
      if obj.startswith(string):
        return True
    return False


  @staticmethod
  def in_any(obj, iterable):
    for item in iterable:
      if obj in item:
        return True
    return False


  @staticmethod
  def startswith_one_of(string, chars):
    return string and string[0] in chars


  @staticmethod
  def raise_outdata_iterable(mapping):
    raise ValueError, 'expecting iterable output data for mapping "%s"' \
                      % mapping

  @staticmethod
  def raise_percent_in_inmap(mapping):
    raise ValueError, 'bad input mapping: "%s"' % mapping

  @staticmethod
  def raise_exec_mode():
    raise ValueError, 'expecting "once", "seq" or "para"'

  @staticmethod
  def raise_parallel():
    raise ValueError, 'parallel execution not possible if not independent'

  @staticmethod
  def raise_indep():
    raise ValueError, 'independent execution not possible if '+\
                      'infiles != outfiles'

  @staticmethod
  def raise_outdata(outlen):
    raise ValueError, 'expecting function result with at least '+\
                      '%i elements' % outlen

  @staticmethod
  def raise_postproc_iter():
    raise ValueError, 'postprocessor must be scalar if output data is scalar'

  @staticmethod
  def raise_postproc_len(outlen):
    raise ValueError, 'list of postprocessors cannot be longer than '+\
                      'function result (%i)' % outlen

  @staticmethod
  def raise_preproc():
    raise ValueError, 'expecting dictionary of callables'

  @staticmethod
  def raise_reqarg_not_in_inmap(reqarg):
    raise ValueError, 'argument "%s" required but missing in input mapping' \
                      % reqarg

  def raise_outmap_len(self, noutdata):
    raise ValueError, 'output mapping too long (function delivered only ' +\
                      '%i output value%s)' \
                      % (noutdata, self.plural(noutdata))

  @staticmethod
  def raise_argind(mapping):
    raise ValueError, 'bad argument index in mapping "%s"' % mapping

  @staticmethod
  def raise_outdata_len(nexpected):
    raise ValueError, 'expected function return value of length %i' \
                      % nexpected

  @staticmethod
  def raise_inmap(mapping):
    raise ValueError, 'bad input mapping "%s"' % mapping

  @staticmethod
  def raise_outmap(mapping):
    raise ValueError, 'bad output mapping "%s"' % mapping

  @staticmethod
  def raise_stdin_structure():
    raise ValueError, 'bad STDIN data structure'

  @staticmethod
  def raise_stdout_structure():
    raise ValueError, 'bad STDOUT data structure'

  def error_pairs(self):
    print >>sys.stderr, '%s: expecting even number of arguments' \
                        % self.prog
    sys.exit(1)

  def error_arg_pairs(self):
    print >>sys.stderr, '%s: expecting same number of output ' % self.prog+\
                        'arguments as number of input arguments'
    sys.exit(1)

  def error_nargs(self, nargs):
    print >>sys.stderr, '%s: expecting exactly %i argument%s' \
                        % (self.prog, nargs, self.plural(nargs))
    sys.exit(1)

  def error_nargs_min(self, nargs):
    print >>sys.stderr, '%s: expecting at least %i argument%s' \
                        % (self.prog, nargs, self.plural(nargs))
    sys.exit(1)

  def error_file(self, filename):
    print >>sys.stderr, '%s: cannot load from "%s": no such file' \
                        % (self.prog, filename)
    sys.exit(1)

  def error_dset_not_found(self, dsetname, filename):
    print >>sys.stderr, '%s: cannot load dataset "%s/%s": no such dataset' \
                        % (self.prog, filename, dsetname)
    sys.exit(1)

  def error_dset_exists(self, dsetname, filename):
    print >>sys.stderr, '%s: dataset already exists: %s/%s' \
                        % (self.prog, filename, dsetname)
    sys.exit(1)

  def error_dset_omit(self, dsetname, filename):
    print >>sys.stderr, '%s: omitting dataset "%s/%s": already exists' \
                        % (self.prog, filename, dsetname)

  def error_shortopt(self, shortopt):
    print >>sys.stderr, '%s: invalid short option "%s"' \
                        % (self.prog, shortopt)
    sys.exit(1)

  def error_stdin_len(self, nlines):
    print >>sys.stderr, '%s: expecting at least %i line%s of STDIN' \
                        % (self.prog, nlines, self.plural(nlines))
    sys.exit(1)

  #def error_arg_len(self, inlen):
    #print >>sys.stderr, '%s: expecting commandline argument with %i ' \
                        #% (self.prog, inlen) +\
                        #'element%s (separated by "%s")' \
                        #% (self.plural(inlen), self.sep_stdin)
    #sys.exit(1)

  @staticmethod
  def plural(number):
    return '' if abs(number) == 1 else 's'

  @staticmethod
  def is_even(number):
    return not number % 2





















#===================================================#
# tools to list frogs and create executable scripts #
#===================================================#


@Frog(postproc=columnize)
def froglist(module):
  """List all frogs defined in a certain module. The module can be a string
  (module path) or the module object itself."""
  if isinstance(module, basestring):
    module = __import__(module, fromlist=['something'])
    # it is an interesting issue why "fromlist" cannot be an empty list if
    # __import__ shall return the rightmost submodule in a module path:
    # http://stackoverflow.com/questions/2724260/why-does-pythons-import
    # -require-fromlist
  names = []
  for name, obj in module.__dict__.iteritems():
    if isfrog(obj): names.append(name)
  names.sort()
  return names


@Frog()
def frogexec(frog, name=None, dir='.'):
  """Create a small executable script that calls the specified frog wrapper.
  Expect either the function object of the frog wrapper itself, or a string
  containing the full module path to the frog wrapper.

  The executable script is created in the directory "dir". Default is the
  current working directory. The script will be named according to "name",
  otherwise it will be based on the name of the function object of the frog
  wrapper.

  An attempt to make the script executable is made, using "chmod +x"."""

  if isinstance(frog, basestring):
    # decode module path
    modulename, frogname = frog.rsplit('.', 1)
    frog = getattr(__import__(modulename, fromlist=['something']), frogname)
  else:
    # get name of module and name of frog wrapper
    modulename, frogname = __name__, frog.__name__

  # check object
  if not isfrog(frog):
    raise ValueError, 'given function object is not a frog'

  # determine filename
  if not name:
    name = frog.__name__
    while name.startswith('_'): name = name[1:]
  path = os.path.relpath(os.path.join(dir, name))
  if os.path.exists(path):
    raise IOError, 'file exists: %s' % path

  # create the file
  with open(path, 'w') as f:
    f.write('#!/usr/bin/env python\n')
    f.write('# -*- coding: utf-8 -*-\n')
    f.write('import sys\n')
    f.write('from %s import %s as frog\n' % (modulename, frogname))
    f.write('sys.exit(frog())\n')

  # try to make it executable
  try:
    os.system('chmod +x %s' % path)
  except:
    print >>sys.stderr, 'warning: unable to change permissions: %s' % path


def isfrog(func):
  """Check if given function object is that of a frog wrapper."""
  return hasattr(func, '__frog__') and func.__frog__


















#===========================================================#
# convenience functions and classes for datatype conversion #
#===========================================================#


class list_of(object):
  """Instances of this class are callables that turn a given iterable into
  a list of items with the specified data type."""
  def __init__(self, dtype):
    self.dtype = dtype
  def __call__(self, iterable):
    iterable = list(iterable)
    for i in xrange(len(iterable)):
      iterable[i] = self.dtype(iterable[i])
    return iterable


class tuple_of(object):
  """Instances of this class are callables that turn a given iterable into
  a tuple of items with the specified data type."""
  def __init__(self, dtype):
    self.dtype = dtype
  def __call__(self, iterable):
    iterable = list(iterable)
    for i in xrange(len(iterable)):
      iterable[i] = self.dtype(iterable[i])
    return tuple(iterable)


def sentence(iterable):
  """Convert all items of the iterable to strings and join them with space
  characters in between. Return the newly formed string."""
  return ' '.join(str(i) for i in iterable)


class apply_all(object):
  """Instances of this class are callables that apply a list of functions to
  the given object."""
  def __init__(self, *funcs):
    self.funcs = funcs
  def __call__(self, obj):
    for func in self.funcs:
      obj = func(obj)
    return obj


def eval_if_str(obj):
  """Evaluate given expression only if string is given, otherwise, leave the
  given object unchanged."""
  return eval(obj) if isinstance(obj, basestring) else obj


def _nicetime(seconds):
  """Return nice string representation of the given number of seconds in a
  human-readable format (approximated). Example: 3634 s --> 1 h."""
  # 2013-08-06
  # copied from progress._nicetime (written 2012-09-04)
  # copied from tb.misc.nicetime (written 2012-02-17)
  from itertools import izip

  # create list of time units (must be sorted from small to large units)
  units = [{'factor': 1,  'name': 'sec'},
           {'factor': 60, 'name': 'min'},
           {'factor': 60, 'name': 'hrs'},
           {'factor': 24, 'name': 'dys'},
           {'factor': 7,  'name': 'wks'},
           {'factor': 4,  'name': 'mns'},
           {'factor': 12, 'name': 'yrs'}]

  value = int(seconds)
  for unit1, unit2 in izip(units[:-1], units[1:]):
    if value/unit2['factor'] == 0:
      return '%i %s' % (value, unit1['name'])
    else:
      value /= unit2['factor']
  return '%i %s' % (value, unit2['name'])
