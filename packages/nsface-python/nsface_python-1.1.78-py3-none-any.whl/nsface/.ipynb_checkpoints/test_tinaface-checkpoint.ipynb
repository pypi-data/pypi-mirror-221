{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45429789-62a4-4527-8669-9995348098f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test inference TinaFace trt (v8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "06e440b0-2b3e-482c-80c0-65112bfadd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "29f7f9c9-ad67-49fc-aef6-102ede869246",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "2e61d15a-949e-4ddc-8266-60ba1f4f4e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_zoo.get_models import get_detection_model,get_landmark_model, get_ageGender_model,get_recognition_model\n",
    "from face.get_result import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "6ae625d5-5427-49a2-82dc-e7c04c711c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.util_common import draw_result,draw_result_sim\n",
    "from data.image import read_image,resize_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "7dcdd35a-a6cd-4b97-bbff-57e591f58826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_zoo.model_common import load_tensorRT,load_onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "0e5f8c31-02e8-45b0-b68b-9386e2bbe7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "ebbc1771-754b-43ec-b442-7ebe3889ed24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/data/notebook/yoonms/vedadet/tinaface_r50_fpn_bn_sim.v8.trt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "3dd868fc-f2e6-4739-af7d-3442f0d90d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04/26/2022-18:44:38] [TRT] [W] TensorRT was linked against cuBLAS/cuBLAS LT 11.6.5 but loaded cuBLAS/cuBLAS LT 11.6.1\n",
      "[04/26/2022-18:44:38] [TRT] [W] TensorRT was linked against cuBLAS/cuBLAS LT 11.6.5 but loaded cuBLAS/cuBLAS LT 11.6.1\n"
     ]
    }
   ],
   "source": [
    "model = load_tensorRT.TrtModel(model_path,not_norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9552b59c-fc74-4972-b1a7-8c80caa9ea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime\n",
    "import cv2\n",
    "\n",
    "onnx_path = \"/data/notebook/yoonms/vedadet/tinaface_r50_fpn_bn_sim.onnx\"\n",
    "onnx_net = cv2.dnn.readNetFromONNX(onnx_path)\n",
    "onnx_net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "onnx_net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "0374c593-6e31-45b2-a9f4-d0aa9c66ece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = read_image(\"/data/notebook/yoonms/GenderAge_inference2/p3.jpg\")\n",
    "img = resize_image(img,(480,640))\n",
    "img_t = read_torchImage(img,not_norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "7e2904d4-9459-428e-8da9-e60e025b84ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_names = [onnx_net.getLayerNames()[i - 1] for i in onnx_net.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "cd172b52-0af0-4715-b6dd-caa77937745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (640,640)\n",
    "blob = cv2.dnn.blobFromImage(img, 1.0/1, input_size, (0,0,0), swapRB=False)\n",
    "\n",
    "onnx_net.setInput(blob)\n",
    "outs = onnx_net.forward(output_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "b9cb1c67-762d-497b-be9f-464c358a0b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_names = sorted(output_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9f241483-68d2-4bcf-95bf-5396522f18e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "strides = [4, 8, 16, 32, 64, 128]\n",
    "use_sigmoid = True\n",
    "scales_per_octave = 3\n",
    "ratios = [1.3]\n",
    "num_anchors = scales_per_octave * len(ratios)\n",
    "meshgrid = dict(\n",
    "    typename='BBoxAnchorMeshGrid',\n",
    "    strides=strides,\n",
    "    base_anchor=dict(\n",
    "        typename='BBoxBaseAnchor',\n",
    "        octave_base_scale=2**(4 / 3),\n",
    "        scales_per_octave=scales_per_octave,\n",
    "        ratios=ratios,\n",
    "        base_sizes=strides))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fd22e578-f870-4c4f-bc10-70d7bf16424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_from_cfg(cfg, registry, module_name='module', default_args=None):\n",
    "    if not isinstance(cfg, dict):\n",
    "        raise TypeError(f'cfg must be a dict, but got {type(cfg)}')\n",
    "    if 'typename' not in cfg:\n",
    "        raise KeyError(\n",
    "            f'the cfg dict must contain the key \"typename\", but got {cfg}')\n",
    "    if not isinstance(registry, Registry):\n",
    "        raise TypeError('registry must be a registry object, '\n",
    "                        f'but got {type(registry)}')\n",
    "    if not (isinstance(default_args, dict) or default_args is None):\n",
    "        raise TypeError('default_args must be a dict or None, '\n",
    "                        f'but got {type(default_args)}')\n",
    "\n",
    "    args = cfg.copy()\n",
    "    obj_type = args.pop('typename')\n",
    "    if is_str(obj_type):\n",
    "        obj_cls = registry.get(obj_type, module_name)\n",
    "    else:\n",
    "        raise TypeError(f'type must be a str, but got {type(obj_type)}')\n",
    "\n",
    "    if default_args is not None:\n",
    "        for name, value in default_args.items():\n",
    "            args.setdefault(name, value)\n",
    "    return obj_cls(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "77536c44-b79d-4a86-b9ab-c16a32734b73",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cfg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [59]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m build_from_cfg(\u001b[43mcfg\u001b[49m,registry,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase_anchor\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cfg' is not defined"
     ]
    }
   ],
   "source": [
    "build_from_cfg(cfg,registry,'base_anchor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b55e03c3-e478-44b9-b24d-f60ffda8f68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'typename': 'BBoxBaseAnchor',\n",
       " 'octave_base_scale': 2.5198420997897464,\n",
       " 'scales_per_octave': 3,\n",
       " 'ratios': [1.3],\n",
       " 'base_sizes': [4, 8, 16, 32, 64, 128]}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meshgrid['base_anchor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1c40c869-1440-4482-8975-07e5549c5552",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_levels = len(strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "996eaee6-7565-4242-891c-25e5be63ed64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 160, 160)\n",
      "(1, 3, 80, 80)\n",
      "(1, 3, 40, 40)\n",
      "(1, 3, 20, 20)\n",
      "(1, 3, 10, 10)\n",
      "(1, 3, 5, 5)\n",
      "(1, 12, 160, 160)\n",
      "(1, 12, 80, 80)\n",
      "(1, 12, 40, 40)\n",
      "(1, 12, 20, 20)\n",
      "(1, 12, 10, 10)\n",
      "(1, 12, 5, 5)\n",
      "(1, 3, 160, 160)\n",
      "(1, 3, 80, 80)\n",
      "(1, 3, 40, 40)\n",
      "(1, 3, 20, 20)\n",
      "(1, 3, 10, 10)\n",
      "(1, 3, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "for o in outs:\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "26207b0c-71ee-4081-af48-deba80c8c09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "featmap_sizes = [feat.shape[-2:] for feat in outs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "176d85ab-9830-4e48-9c9d-39fb6f87c547",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = outs[0].dtype\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "73601184-53cc-4e1f-9ea2-57a599cd6f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "badda79b-2f3a-4e0d-a097-d05cd2e8b867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'typename': 'BBoxAnchorMeshGrid',\n",
       " 'strides': [4, 8, 16, 32, 64, 128],\n",
       " 'base_anchor': {'typename': 'BBoxBaseAnchor',\n",
       "  'octave_base_scale': 2.5198420997897464,\n",
       "  'scales_per_octave': 3,\n",
       "  'ratios': [1.3],\n",
       "  'base_sizes': [4, 8, 16, 32, 64, 128]}}"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meshgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "8088e483-bfae-4b90-b06c-7d5fa3838944",
   "metadata": {},
   "outputs": [],
   "source": [
    "strides = [4, 8, 16, 32, 64, 128]\n",
    "use_sigmoid = True\n",
    "scales_per_octave = 3\n",
    "ratios = [1.3]\n",
    "num_anchors = scales_per_octave * len(ratios)\n",
    "meshgrid = dict(\n",
    "    typename='BBoxAnchorMeshGrid',\n",
    "    strides=strides,\n",
    "    base_anchor=dict(\n",
    "        typename='BBoxBaseAnchor',\n",
    "        octave_base_scale=2**(4 / 3),\n",
    "        scales_per_octave=scales_per_octave,\n",
    "        ratios=ratios,\n",
    "        base_sizes=strides))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "c3c95b68-7d77-46bf-a4b2-680a98200181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "e328d978-58da-41a7-8b21-7df2820a88e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "bdbda79a-683d-4b2d-b8d5-0df81e6b1f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_anchor = BBoxBaseAnchor(ratios=ratios,base_sizes=strides, octave_base_scale=2**(4 / 3),scales_per_octave=3).generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "8917a208-1e92-4396-b7b8-fb72a50c958d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-4.4201, -5.7461,  4.4201,  5.7461],\n",
       "         [-5.5690, -7.2397,  5.5690,  7.2397],\n",
       "         [-7.0165, -9.1214,  7.0165,  9.1214]]),\n",
       " tensor([[ -8.8402, -11.4922,   8.8402,  11.4922],\n",
       "         [-11.1379, -14.4793,  11.1379,  14.4793],\n",
       "         [-14.0329, -18.2428,  14.0329,  18.2428]]),\n",
       " tensor([[-17.6804, -22.9845,  17.6804,  22.9845],\n",
       "         [-22.2759, -28.9587,  22.2759,  28.9587],\n",
       "         [-28.0659, -36.4856,  28.0659,  36.4856]]),\n",
       " tensor([[-35.3608, -45.9690,  35.3608,  45.9690],\n",
       "         [-44.5518, -57.9173,  44.5518,  57.9173],\n",
       "         [-56.1317, -72.9712,  56.1317,  72.9712]]),\n",
       " tensor([[ -70.7215,  -91.9380,   70.7215,   91.9380],\n",
       "         [ -89.1035, -115.8346,   89.1035,  115.8346],\n",
       "         [-112.2634, -145.9425,  112.2634,  145.9425]]),\n",
       " tensor([[-141.4431, -183.8760,  141.4431,  183.8760],\n",
       "         [-178.2071, -231.6692,  178.2071,  231.6692],\n",
       "         [-224.5268, -291.8849,  224.5268,  291.8849]])]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa88caf-7735-4271-ac9d-2432331a4f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "d27ceb62-da0e-40e2-87bd-bd67d5794662",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"/data/notebook/yoonms/GenderAge_inference2/p3.jpg\"\n",
    "img = cv2.imread(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "c30d3bed-9893-47ca-ae3c-d299ae4319aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [dict(img=img)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "153998c2-8352-4ca3-9eab-b37e6997bee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9b2dbe4-8603-4f89-b86a-fe5472ebbf2f",
   "metadata": {},
   "source": [
    "# ImageToGray\n",
    "img = data['img']\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)[:, :, np.newaxis]\n",
    "data['img'] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "aefcf20f-b2a3-488b-86f3-c3fb25140170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize\n",
    "dst_shape = [640,640]\n",
    "interp = cv2.INTER_LINEAR\n",
    "keep_ratio = False\n",
    "\n",
    "img = data['img']\n",
    "h, w = img.shape[:2]\n",
    "new_h, new_w = dst_shape\n",
    "if keep_ratio:\n",
    "    scale_factor = min(max(new_h, new_w) / max(h, w), min(new_h, new_w) / min(h, w))\n",
    "    new_h = int(h * float(scale_factor) + 0.5)\n",
    "    new_w = int(w * float(scale_factor) + 0.5)\n",
    "\n",
    "img = cv2.resize(img, (new_w, new_h), interpolation=interp)  # TODO time consuming\n",
    "w_scale = new_w / w\n",
    "h_scale = new_h / h\n",
    "\n",
    "scale_factor = np.array([w_scale, h_scale, w_scale, h_scale],\n",
    "                        dtype=np.float32)\n",
    "\n",
    "data['img'] = img\n",
    "data['img_shape'] = img.shape\n",
    "data['pad_shape'] = img.shape\n",
    "data['scale_factor'] = scale_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "c17998d0-e9bb-4e64-b331-86fb443c0095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 640, 3)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['pad_shape']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "a3f60577-1603-48ea-a7c9-f4b05a73e329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PadIfNeeded\n",
    "\n",
    "size = None\n",
    "size_divisor = 32\n",
    "mode = cv2.BORDER_CONSTANT\n",
    "value = np.array([123.675, 116.280, 103.530])\n",
    "\n",
    "img = data['img']\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "if size is not None:\n",
    "    pad_h, pad_w = size\n",
    "    assert h <= pad_h and w <= pad_w\n",
    "else:\n",
    "    pad_h = int(np.ceil(h / size_divisor)) * size_divisor\n",
    "    pad_w = int(np.ceil(w / size_divisor)) * size_divisor\n",
    "padded_img = cv2.copyMakeBorder(img, 0, pad_h - h, 0, pad_w - w,\n",
    "                                mode, value=value)\n",
    "\n",
    "data['img'] = padded_img\n",
    "data['img_shape'] = img.shape\n",
    "data['pad_shape'] = padded_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "0b0951a4-ef32-47cf-b6da-fcc24328f419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageToTensor\n",
    "\n",
    "use_gpu=False\n",
    "\n",
    "img = data['img']\n",
    "if img.ndim == 2:\n",
    "    img = img[:, :, None]\n",
    "img = torch.from_numpy(img)\n",
    "if use_gpu:\n",
    "    img = img.cuda()\n",
    "img = img.permute(2, 0, 1)  # h*w*c -> c*h*w\n",
    "img = img.float()\n",
    "img = img.unsqueeze(0)  # c*h*w -> 1*c*h*w\n",
    "\n",
    "data['img'] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "194c8dde-4825-4980-b981-3978f6b7b7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 640, 640])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "523b2bdb-39f4-4b46-905e-730cd84762a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "\n",
    "mean=[123.675, 116.28, 103.53]\n",
    "std=[1,1,1]\n",
    "use_gpu=False\n",
    "gray=False\n",
    "to_rgb=True\n",
    "\n",
    "shape = (1, 1, 1, 1) if gray else (1, 3, 1, 1)\n",
    "\n",
    "mean = torch.tensor(mean, dtype=torch.float32).view(*shape)\n",
    "std = torch.tensor(std, dtype=torch.float32).view(*shape)\n",
    "gray = gray\n",
    "to_rgb = to_rgb\n",
    "if use_gpu:\n",
    "    mean = mean.cuda()\n",
    "    std = std.cuda()\n",
    "    \n",
    "img = data['img']\n",
    "if not gray and to_rgb:\n",
    "    # n*c*h*w\n",
    "    img = img[:, [2, 1, 0], :, :]  # bgr to rgb\n",
    "img = (img - mean) / std  # time consuming on cpu\n",
    "\n",
    "data['img'] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "e22a2201-007d-460a-aa17-dabd19706527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img': tensor([[[[ 11.3250,  16.3250,  16.3250,  ...,  16.3250,  19.3250,  24.3250],\n",
       "           [ 11.3250,  16.3250,  16.3250,  ...,  20.3250,  22.3250,  23.3250],\n",
       "           [ 11.3250,  17.3250,  17.3250,  ...,  22.3250,  22.3250,  22.3250],\n",
       "           ...,\n",
       "           [-50.6750, -50.6750, -50.6750,  ..., -22.6750, -13.6750,  -1.6750],\n",
       "           [-50.6750, -50.6750, -50.6750,  ..., -27.6750, -26.6750,  -7.6750],\n",
       "           [-50.6750, -50.6750, -50.6750,  ..., -22.6750, -37.6750, -18.6750]],\n",
       " \n",
       "          [[ 17.7200,  22.7200,  22.7200,  ...,  24.7200,  28.7200,  32.7200],\n",
       "           [ 17.7200,  22.7200,  22.7200,  ...,  28.7200,  30.7200,  32.7200],\n",
       "           [ 17.7200,  22.7200,  22.7200,  ...,  30.7200,  31.7200,  31.7200],\n",
       "           ...,\n",
       "           [-43.2800, -43.2800, -43.2800,  ...,  -3.2800,   4.7200,  16.7200],\n",
       "           [-43.2800, -43.2800, -43.2800,  ...,  -8.2800,  -8.2800,  10.7200],\n",
       "           [-43.2800, -43.2800, -43.2800,  ...,  -4.2800, -18.2800,  -0.2800]],\n",
       " \n",
       "          [[ 30.4700,  35.4700,  34.4700,  ...,  37.4700,  40.4700,  45.4700],\n",
       "           [ 31.4700,  35.4700,  34.4700,  ...,  41.4700,  43.4700,  44.4700],\n",
       "           [ 32.4700,  36.4700,  34.4700,  ...,  43.4700,  43.4700,  43.4700],\n",
       "           ...,\n",
       "           [-32.5300, -32.5300, -32.5300,  ...,   9.4700,  18.4700,  29.4700],\n",
       "           [-32.5300, -32.5300, -32.5300,  ...,   4.4700,   5.4700,  24.4700],\n",
       "           [-32.5300, -32.5300, -32.5300,  ...,  10.4700,  -4.5300,  13.4700]]]]),\n",
       " 'img_shape': (640, 640, 3),\n",
       " 'pad_shape': (640, 640, 3),\n",
       " 'scale_factor': array([0.52117264, 0.6956522 , 0.52117264, 0.6956522 ], dtype=float32)}"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e192138-854a-4291-bbd5-36b7a52abd8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "709a111c-5fe0-497e-834f-c4d012056106",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT = dict(\n",
    "    scale_factor=1.0,\n",
    "    flip=False,\n",
    "    flip_direction=None,\n",
    ")\n",
    "\n",
    "# Collect\n",
    "\n",
    "keys = data.keys()\n",
    "meta_keys = ['img_shape', 'pad_shape', 'scale_factor', 'flip', 'flip_direction']\n",
    "\n",
    "data_ = {}\n",
    "img_meta = {}\n",
    "\n",
    "for key in meta_keys:\n",
    "    if key in data:\n",
    "        img_meta[key] = data[key]\n",
    "    else:\n",
    "        img_meta[key] = DEFAULT[key]\n",
    "\n",
    "for key in keys:\n",
    "    data_[key] = data[key]\n",
    "data_['img_metas'] = img_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "69de2e0c-28cb-49fc-9241-9b65a77f2684",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "0b49ce93-0a11-4bb4-8bc9-6feb5f76cc7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img': tensor([[[[ 11.3250,  16.3250,  16.3250,  ...,  16.3250,  19.3250,  24.3250],\n",
       "           [ 11.3250,  16.3250,  16.3250,  ...,  20.3250,  22.3250,  23.3250],\n",
       "           [ 11.3250,  17.3250,  17.3250,  ...,  22.3250,  22.3250,  22.3250],\n",
       "           ...,\n",
       "           [-50.6750, -50.6750, -50.6750,  ..., -22.6750, -13.6750,  -1.6750],\n",
       "           [-50.6750, -50.6750, -50.6750,  ..., -27.6750, -26.6750,  -7.6750],\n",
       "           [-50.6750, -50.6750, -50.6750,  ..., -22.6750, -37.6750, -18.6750]],\n",
       " \n",
       "          [[ 17.7200,  22.7200,  22.7200,  ...,  24.7200,  28.7200,  32.7200],\n",
       "           [ 17.7200,  22.7200,  22.7200,  ...,  28.7200,  30.7200,  32.7200],\n",
       "           [ 17.7200,  22.7200,  22.7200,  ...,  30.7200,  31.7200,  31.7200],\n",
       "           ...,\n",
       "           [-43.2800, -43.2800, -43.2800,  ...,  -3.2800,   4.7200,  16.7200],\n",
       "           [-43.2800, -43.2800, -43.2800,  ...,  -8.2800,  -8.2800,  10.7200],\n",
       "           [-43.2800, -43.2800, -43.2800,  ...,  -4.2800, -18.2800,  -0.2800]],\n",
       " \n",
       "          [[ 30.4700,  35.4700,  34.4700,  ...,  37.4700,  40.4700,  45.4700],\n",
       "           [ 31.4700,  35.4700,  34.4700,  ...,  41.4700,  43.4700,  44.4700],\n",
       "           [ 32.4700,  36.4700,  34.4700,  ...,  43.4700,  43.4700,  43.4700],\n",
       "           ...,\n",
       "           [-32.5300, -32.5300, -32.5300,  ...,   9.4700,  18.4700,  29.4700],\n",
       "           [-32.5300, -32.5300, -32.5300,  ...,   4.4700,   5.4700,  24.4700],\n",
       "           [-32.5300, -32.5300, -32.5300,  ...,  10.4700,  -4.5300,  13.4700]]]]),\n",
       " 'img_shape': (640, 640, 3),\n",
       " 'pad_shape': (640, 640, 3),\n",
       " 'scale_factor': array([0.52117264, 0.6956522 , 0.52117264, 0.6956522 ], dtype=float32),\n",
       " 'img_metas': {'img_shape': (640, 640, 3),\n",
       "  'pad_shape': (640, 640, 3),\n",
       "  'scale_factor': array([0.52117264, 0.6956522 , 0.52117264, 0.6956522 ], dtype=float32),\n",
       "  'flip': False,\n",
       "  'flip_direction': None}}"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc75b5ff-d7f1-4fde-8705-e4b8d3273311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c212d3-65da-4cd7-8cbc-8e62394f41d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "23837c47-d547-404e-b08f-7924a32c3967",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-4.4201, -5.7461,  4.4201,  5.7461],\n",
       "         [-5.5690, -7.2397,  5.5690,  7.2397],\n",
       "         [-7.0165, -9.1214,  7.0165,  9.1214]]),\n",
       " tensor([[ -8.8402, -11.4922,   8.8402,  11.4922],\n",
       "         [-11.1379, -14.4793,  11.1379,  14.4793],\n",
       "         [-14.0329, -18.2428,  14.0329,  18.2428]]),\n",
       " tensor([[-17.6804, -22.9845,  17.6804,  22.9845],\n",
       "         [-22.2759, -28.9587,  22.2759,  28.9587],\n",
       "         [-28.0659, -36.4856,  28.0659,  36.4856]]),\n",
       " tensor([[-35.3608, -45.9690,  35.3608,  45.9690],\n",
       "         [-44.5518, -57.9173,  44.5518,  57.9173],\n",
       "         [-56.1317, -72.9712,  56.1317,  72.9712]]),\n",
       " tensor([[ -70.7215,  -91.9380,   70.7215,   91.9380],\n",
       "         [ -89.1035, -115.8346,   89.1035,  115.8346],\n",
       "         [-112.2634, -145.9425,  112.2634,  145.9425]]),\n",
       " tensor([[-141.4431, -183.8760,  141.4431,  183.8760],\n",
       "         [-178.2071, -231.6692,  178.2071,  231.6692],\n",
       "         [-224.5268, -291.8849,  224.5268,  291.8849]])]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "b404bd57-db8a-43d3-8895-ad979bb62b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _num_base_anchors(base_anchors):\n",
    "    \"\"\"list[int]: total number of base anchors in a feature grid\"\"\"\n",
    "    return [base_anchor.size(0) for base_anchor in base_anchors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "620d5858-e27e-4fcf-8a28-1a73554bd27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_base_anchors = _num_base_anchors(base_anchor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "b459d1a3-fb74-4318-8f46-bcb304ce4c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _meshgrid(x, y, row_major=True):\n",
    "        \"\"\"Generate mesh grid of x and y.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Grids of x dimension.\n",
    "            y (torch.Tensor): Grids of y dimension.\n",
    "            row_major (bool, optional): Whether to return y grids first.\n",
    "                Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "            tuple[torch.Tensor]: The mesh grids of x and y.\n",
    "        \"\"\"\n",
    "        xx = x.repeat(len(y))\n",
    "        yy = y.view(-1, 1).repeat(1, len(x)).view(-1)\n",
    "        if row_major:\n",
    "            return xx, yy\n",
    "        else:\n",
    "            return yy, xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "a97dffc7-6d96-4120-a255-5ac50058640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _single_level_anchor_mesh(base_anchors, featmap_size, stride,\n",
    "                                  device):\n",
    "        \"\"\"Generate grid anchors of a single level.\n",
    "\n",
    "        Note:\n",
    "            This function is usually called by method ``self.grid_anchors``.\n",
    "\n",
    "        Args:\n",
    "            base_anchors (torch.Tensor): The base anchors of a feature grid.\n",
    "            featmap_size (tuple[int]): Size of the feature maps.\n",
    "            stride (tuple[int], optional): Stride of the feature map.\n",
    "                Defaults to (16, 16).\n",
    "            device (str, optional): Device the tensor will be put on.\n",
    "                Defaults to 'cuda'.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Anchors in the overall feature maps.\n",
    "        \"\"\"\n",
    "        feat_h, feat_w = featmap_size\n",
    "        # shift_x = torch.arange(0, feat_w, device=device) * stride[0]\n",
    "        # shift_y = torch.arange(0, feat_h, device=device) * stride[1]\n",
    "        shift_x = torch.arange(0, feat_w, device=device) * stride\n",
    "        shift_y = torch.arange(0, feat_h, device=device) * stride\n",
    "        shift_xx, shift_yy = _meshgrid(shift_x, shift_y)\n",
    "        shifts = torch.stack([shift_xx, shift_yy, shift_xx, shift_yy], dim=-1)\n",
    "        shifts = shifts.type_as(base_anchors)\n",
    "        # first feat_w elements correspond to the first row of shifts\n",
    "        # add A anchors (1, A, 4) to K shifts (K, 1, 4) to get\n",
    "        # shifted anchors (K, A, 4), reshape to (K*A, 4)\n",
    "\n",
    "        all_anchors = base_anchors[None, :, :] + shifts[:, None, :]\n",
    "        all_anchors = all_anchors.view(-1, 4)\n",
    "        # first A rows correspond to A anchors of (0, 0) in feature map,\n",
    "        # then (0, 1), (0, 2), ...\n",
    "        return all_anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "4892d507-21cb-45c6-93e4-6f7e2bf4be30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _single_level_valid_flags(featmap_size,\n",
    "                                  valid_size,\n",
    "                                  num_base_anchors,\n",
    "                                  device='cuda'):\n",
    "        \"\"\"Generate the valid flags of anchor in a single feature map.\n",
    "        Args:\n",
    "            featmap_size (tuple[int]): The size of feature maps.\n",
    "            valid_size (tuple[int]): The valid size of the feature maps.\n",
    "            num_base_anchors (int): The number of base anchors.\n",
    "            device (str, optional): Device where the flags will be put on.\n",
    "                Defaults to 'cuda'.\n",
    "        Returns:\n",
    "            torch.Tensor: The valid flags of each anchor in a single level\n",
    "                feature map.\n",
    "        \"\"\"\n",
    "        feat_h, feat_w = featmap_size\n",
    "        valid_h, valid_w = valid_size\n",
    "        assert valid_h <= feat_h and valid_w <= feat_w\n",
    "        valid_x = torch.zeros(feat_w, dtype=torch.bool, device=device)\n",
    "        valid_y = torch.zeros(feat_h, dtype=torch.bool, device=device)\n",
    "        valid_x[:valid_w] = 1\n",
    "        valid_y[:valid_h] = 1\n",
    "        valid_xx, valid_yy = _meshgrid(valid_x, valid_y)\n",
    "        valid = valid_xx & valid_yy\n",
    "        valid = valid[:, None].expand(valid.size(0),\n",
    "                                      num_base_anchors).contiguous().view(-1)\n",
    "        return valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "525fde4a-e85f-4c08-b057-c5e2eae28eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_flags(featmap_sizes, pad_shape, device='cuda'):\n",
    "        \"\"\"Generate valid flags of anchors in multiple feature levels.\n",
    "        Args:\n",
    "            featmap_sizes (list(tuple)): List of feature map sizes in\n",
    "                multiple feature levels.\n",
    "            pad_shape (tuple): The padded shape of the image.\n",
    "            device (str): Device where the anchors will be put on.\n",
    "        Return:\n",
    "            list(torch.Tensor): Valid flags of anchors in multiple levels.\n",
    "        \"\"\"\n",
    "        assert num_levels == len(featmap_sizes)\n",
    "        multi_level_flags = []\n",
    "        for i in range(num_levels):\n",
    "            anchor_stride = strides[i]\n",
    "            feat_h, feat_w = featmap_sizes[i]\n",
    "            h, w = pad_shape[:2]\n",
    "            # valid_feat_h = min(int(np.ceil(h / anchor_stride[0])), feat_h)\n",
    "            # valid_feat_w = min(int(np.ceil(w / anchor_stride[1])), feat_w)\n",
    "            valid_feat_h = min(int(np.ceil(h / anchor_stride)), feat_h)\n",
    "            valid_feat_w = min(int(np.ceil(w / anchor_stride)), feat_w)\n",
    "            flags = _single_level_valid_flags(\n",
    "                (feat_h, feat_w), (valid_feat_h, valid_feat_w),\n",
    "                num_base_anchors[i],\n",
    "                device=device)\n",
    "            multi_level_flags.append(flags)\n",
    "        return multi_level_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "eff528ec-5415-42d5-a50d-ade1a347185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gen_anchor_mesh(featmap_sizes, dtype, device):\n",
    "        \"\"\"Get points according to feature map sizes.\n",
    "        Args:\n",
    "            featmap_sizes (list[tuple]): Multi-level feature map sizes.\n",
    "            dtype (torch.dtype): Type of points.\n",
    "            device (torch.device): Device of points.\n",
    "        Returns:\n",
    "            tuple: points of each image.\n",
    "        \"\"\"\n",
    "        print(num_levels, len(featmap_sizes))\n",
    "        assert num_levels == len(featmap_sizes)\n",
    "        multi_level_anchors = []\n",
    "        for i in range(num_levels):\n",
    "            anchors = _single_level_anchor_mesh(\n",
    "                base_anchors[i].to(device).to(dtype),\n",
    "                featmap_sizes[i],\n",
    "                strides[i],\n",
    "                device=device)\n",
    "            multi_level_anchors.append(anchors)\n",
    "        return multi_level_anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "8be540eb-45a2-4b0d-ae5c-6925e0adfa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_anchor_mesh(featmap_sizes,\n",
    "                        img_metas,\n",
    "                        dtype=torch.float,\n",
    "                        device='cuda'):\n",
    "    num_imgs = 1\n",
    "\n",
    "    # since feature map sizes of all images are the same, we only compute\n",
    "    # anchors for one time\n",
    "    multi_level_anchors = _gen_anchor_mesh(featmap_sizes, dtype,\n",
    "                                                    'cpu')\n",
    "    anchor_list = [multi_level_anchors for _ in range(num_imgs)]\n",
    "\n",
    "    # for each image, we compute valid flags of multi level anchors\n",
    "    valid_flag_list = []\n",
    "    for img_id, img_meta in enumerate(img_metas):\n",
    "        multi_level_flags = valid_flags(featmap_sizes,\n",
    "                                                 img_metas['pad_shape'], device)\n",
    "        valid_flag_list.append(multi_level_flags)\n",
    "\n",
    "    return anchor_list, valid_flag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "a5876443-8675-49d6-b572-63230f777169",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_fpn_lvls = len(strides)\n",
    "feats_len = len(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "56aad28b-af92-4b7f-abf0-966018bc1308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 18\n"
     ]
    }
   ],
   "source": [
    "print(num_fpn_lvls, feats_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "322a6aa9-5230-45b1-8adb-cb75db5cc8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [outs[i:i + num_fpn_lvls] for i in range(0, feats_len, num_fpn_lvls)]\n",
    "\n",
    "featmap_sizes = [feat.shape[-2:] for feat in feats[0]]\n",
    "dtype = feats[0][0].dtype\n",
    "#device = feats[0][0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "817b4373-3797-444b-bff3-7d579729b52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(160, 160), (80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featmap_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "62fe2985-967f-45bd-8f31-71004428881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_anchors = BBoxBaseAnchor(ratios=ratios,base_sizes=strides, octave_base_scale=2**(4 / 3),scales_per_octave=3).generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "c744cde0-f425-4ded-9c92-067e50d2e98f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-4.4201, -5.7461,  4.4201,  5.7461],\n",
       "         [-5.5690, -7.2397,  5.5690,  7.2397],\n",
       "         [-7.0165, -9.1214,  7.0165,  9.1214]]),\n",
       " tensor([[ -8.8402, -11.4922,   8.8402,  11.4922],\n",
       "         [-11.1379, -14.4793,  11.1379,  14.4793],\n",
       "         [-14.0329, -18.2428,  14.0329,  18.2428]]),\n",
       " tensor([[-17.6804, -22.9845,  17.6804,  22.9845],\n",
       "         [-22.2759, -28.9587,  22.2759,  28.9587],\n",
       "         [-28.0659, -36.4856,  28.0659,  36.4856]]),\n",
       " tensor([[-35.3608, -45.9690,  35.3608,  45.9690],\n",
       "         [-44.5518, -57.9173,  44.5518,  57.9173],\n",
       "         [-56.1317, -72.9712,  56.1317,  72.9712]]),\n",
       " tensor([[ -70.7215,  -91.9380,   70.7215,   91.9380],\n",
       "         [ -89.1035, -115.8346,   89.1035,  115.8346],\n",
       "         [-112.2634, -145.9425,  112.2634,  145.9425]]),\n",
       " tensor([[-141.4431, -183.8760,  141.4431,  183.8760],\n",
       "         [-178.2071, -231.6692,  178.2071,  231.6692],\n",
       "         [-224.5268, -291.8849,  224.5268,  291.8849]])]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "cc4781db-8c9f-40d7-978f-7aa04a3736fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6\n"
     ]
    }
   ],
   "source": [
    "anchor_mesh = gen_anchor_mesh(featmap_sizes,final_data['img_metas'],device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "5e622e8f-8088-4a1f-87f8-9d4e535f134b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[tensor([[ -4.4201,  -5.7461,   4.4201,   5.7461],\n",
       "           [ -5.5690,  -7.2397,   5.5690,   7.2397],\n",
       "           [ -7.0165,  -9.1214,   7.0165,   9.1214],\n",
       "           ...,\n",
       "           [631.5799, 630.2539, 640.4201, 641.7461],\n",
       "           [630.4310, 628.7603, 641.5690, 643.2397],\n",
       "           [628.9835, 626.8786, 643.0165, 645.1214]]),\n",
       "   tensor([[ -8.8402, -11.4922,   8.8402,  11.4922],\n",
       "           [-11.1379, -14.4793,  11.1379,  14.4793],\n",
       "           [-14.0329, -18.2428,  14.0329,  18.2428],\n",
       "           ...,\n",
       "           [623.1598, 620.5078, 640.8402, 643.4922],\n",
       "           [620.8621, 617.5207, 643.1379, 646.4793],\n",
       "           [617.9671, 613.7572, 646.0329, 650.2428]]),\n",
       "   tensor([[-17.6804, -22.9845,  17.6804,  22.9845],\n",
       "           [-22.2759, -28.9587,  22.2759,  28.9587],\n",
       "           [-28.0659, -36.4856,  28.0659,  36.4856],\n",
       "           ...,\n",
       "           [606.3196, 601.0155, 641.6804, 646.9845],\n",
       "           [601.7241, 595.0413, 646.2759, 652.9587],\n",
       "           [595.9341, 587.5144, 652.0659, 660.4856]]),\n",
       "   tensor([[-35.3608, -45.9690,  35.3608,  45.9690],\n",
       "           [-44.5518, -57.9173,  44.5518,  57.9173],\n",
       "           [-56.1317, -72.9712,  56.1317,  72.9712],\n",
       "           ...,\n",
       "           [572.6392, 562.0310, 643.3608, 653.9690],\n",
       "           [563.4482, 550.0827, 652.5518, 665.9173],\n",
       "           [551.8683, 535.0287, 664.1317, 680.9713]]),\n",
       "   tensor([[ -70.7215,  -91.9380,   70.7215,   91.9380],\n",
       "           [ -89.1035, -115.8346,   89.1035,  115.8346],\n",
       "           [-112.2634, -145.9425,  112.2634,  145.9425],\n",
       "           ...,\n",
       "           [ 505.2785,  484.0620,  646.7216,  667.9380],\n",
       "           [ 486.8965,  460.1654,  665.1035,  691.8346],\n",
       "           [ 463.7366,  430.0576,  688.2634,  721.9424]]),\n",
       "   tensor([[-141.4431, -183.8760,  141.4431,  183.8760],\n",
       "           [-178.2071, -231.6692,  178.2071,  231.6692],\n",
       "           [-224.5268, -291.8849,  224.5268,  291.8849],\n",
       "           [ -13.4431, -183.8760,  269.4431,  183.8760],\n",
       "           [ -50.2071, -231.6692,  306.2071,  231.6692],\n",
       "           [ -96.5268, -291.8849,  352.5269,  291.8849],\n",
       "           [ 114.5569, -183.8760,  397.4431,  183.8760],\n",
       "           [  77.7929, -231.6692,  434.2071,  231.6692],\n",
       "           [  31.4732, -291.8849,  480.5269,  291.8849],\n",
       "           [ 242.5569, -183.8760,  525.4431,  183.8760],\n",
       "           [ 205.7929, -231.6692,  562.2070,  231.6692],\n",
       "           [ 159.4732, -291.8849,  608.5269,  291.8849],\n",
       "           [ 370.5569, -183.8760,  653.4431,  183.8760],\n",
       "           [ 333.7929, -231.6692,  690.2070,  231.6692],\n",
       "           [ 287.4731, -291.8849,  736.5269,  291.8849],\n",
       "           [-141.4431,  -55.8760,  141.4431,  311.8760],\n",
       "           [-178.2071, -103.6692,  178.2071,  359.6692],\n",
       "           [-224.5268, -163.8849,  224.5268,  419.8849],\n",
       "           [ -13.4431,  -55.8760,  269.4431,  311.8760],\n",
       "           [ -50.2071, -103.6692,  306.2071,  359.6692],\n",
       "           [ -96.5268, -163.8849,  352.5269,  419.8849],\n",
       "           [ 114.5569,  -55.8760,  397.4431,  311.8760],\n",
       "           [  77.7929, -103.6692,  434.2071,  359.6692],\n",
       "           [  31.4732, -163.8849,  480.5269,  419.8849],\n",
       "           [ 242.5569,  -55.8760,  525.4431,  311.8760],\n",
       "           [ 205.7929, -103.6692,  562.2070,  359.6692],\n",
       "           [ 159.4732, -163.8849,  608.5269,  419.8849],\n",
       "           [ 370.5569,  -55.8760,  653.4431,  311.8760],\n",
       "           [ 333.7929, -103.6692,  690.2070,  359.6692],\n",
       "           [ 287.4731, -163.8849,  736.5269,  419.8849],\n",
       "           [-141.4431,   72.1240,  141.4431,  439.8760],\n",
       "           [-178.2071,   24.3308,  178.2071,  487.6692],\n",
       "           [-224.5268,  -35.8849,  224.5268,  547.8849],\n",
       "           [ -13.4431,   72.1240,  269.4431,  439.8760],\n",
       "           [ -50.2071,   24.3308,  306.2071,  487.6692],\n",
       "           [ -96.5268,  -35.8849,  352.5269,  547.8849],\n",
       "           [ 114.5569,   72.1240,  397.4431,  439.8760],\n",
       "           [  77.7929,   24.3308,  434.2071,  487.6692],\n",
       "           [  31.4732,  -35.8849,  480.5269,  547.8849],\n",
       "           [ 242.5569,   72.1240,  525.4431,  439.8760],\n",
       "           [ 205.7929,   24.3308,  562.2070,  487.6692],\n",
       "           [ 159.4732,  -35.8849,  608.5269,  547.8849],\n",
       "           [ 370.5569,   72.1240,  653.4431,  439.8760],\n",
       "           [ 333.7929,   24.3308,  690.2070,  487.6692],\n",
       "           [ 287.4731,  -35.8849,  736.5269,  547.8849],\n",
       "           [-141.4431,  200.1240,  141.4431,  567.8760],\n",
       "           [-178.2071,  152.3308,  178.2071,  615.6692],\n",
       "           [-224.5268,   92.1151,  224.5268,  675.8849],\n",
       "           [ -13.4431,  200.1240,  269.4431,  567.8760],\n",
       "           [ -50.2071,  152.3308,  306.2071,  615.6692],\n",
       "           [ -96.5268,   92.1151,  352.5269,  675.8849],\n",
       "           [ 114.5569,  200.1240,  397.4431,  567.8760],\n",
       "           [  77.7929,  152.3308,  434.2071,  615.6692],\n",
       "           [  31.4732,   92.1151,  480.5269,  675.8849],\n",
       "           [ 242.5569,  200.1240,  525.4431,  567.8760],\n",
       "           [ 205.7929,  152.3308,  562.2070,  615.6692],\n",
       "           [ 159.4732,   92.1151,  608.5269,  675.8849],\n",
       "           [ 370.5569,  200.1240,  653.4431,  567.8760],\n",
       "           [ 333.7929,  152.3308,  690.2070,  615.6692],\n",
       "           [ 287.4731,   92.1151,  736.5269,  675.8849],\n",
       "           [-141.4431,  328.1240,  141.4431,  695.8760],\n",
       "           [-178.2071,  280.3308,  178.2071,  743.6692],\n",
       "           [-224.5268,  220.1151,  224.5268,  803.8849],\n",
       "           [ -13.4431,  328.1240,  269.4431,  695.8760],\n",
       "           [ -50.2071,  280.3308,  306.2071,  743.6692],\n",
       "           [ -96.5268,  220.1151,  352.5269,  803.8849],\n",
       "           [ 114.5569,  328.1240,  397.4431,  695.8760],\n",
       "           [  77.7929,  280.3308,  434.2071,  743.6692],\n",
       "           [  31.4732,  220.1151,  480.5269,  803.8849],\n",
       "           [ 242.5569,  328.1240,  525.4431,  695.8760],\n",
       "           [ 205.7929,  280.3308,  562.2070,  743.6692],\n",
       "           [ 159.4732,  220.1151,  608.5269,  803.8849],\n",
       "           [ 370.5569,  328.1240,  653.4431,  695.8760],\n",
       "           [ 333.7929,  280.3308,  690.2070,  743.6692],\n",
       "           [ 287.4731,  220.1151,  736.5269,  803.8849]])]],\n",
       " [[tensor([True, True, True,  ..., True, True, True]),\n",
       "   tensor([True, True, True,  ..., True, True, True]),\n",
       "   tensor([True, True, True,  ..., True, True, True]),\n",
       "   tensor([True, True, True,  ..., True, True, True]),\n",
       "   tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True]),\n",
       "   tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True])],\n",
       "  [tensor([True, True, True,  ..., True, True, True]),\n",
       "   tensor([True, True, True,  ..., True, True, True]),\n",
       "   tensor([True, True, True,  ..., True, True, True]),\n",
       "   tensor([True, True, True,  ..., True, True, True]),\n",
       "   tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True]),\n",
       "   tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True])],\n",
       "  [tensor([True, True, True,  ..., True, True, True]),\n",
       "   tensor([True, True, True,  ..., True, True, True]),\n",
       "   tensor([True, True, True,  ..., True, True, True]),\n",
       "   tensor([True, True, True,  ..., True, True, True]),\n",
       "   tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True]),\n",
       "   tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True])],\n",
       "  [tensor([True, True, True,  ..., True, True, True]),\n",
       "   tensor([True, True, True,  ..., True, True, True]),\n",
       "   tensor([True, True, True,  ..., True, True, True]),\n",
       "   tensor([True, True, True,  ..., True, True, True]),\n",
       "   tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True]),\n",
       "   tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True])],\n",
       "  [tensor([True, True, True,  ..., True, True, True]),\n",
       "   tensor([True, True, True,  ..., True, True, True]),\n",
       "   tensor([True, True, True,  ..., True, True, True]),\n",
       "   tensor([True, True, True,  ..., True, True, True]),\n",
       "   tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True]),\n",
       "   tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True])]])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "40937d4e-5f77-4a51-b04d-2059101516ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dets = self.converter.get_bboxes(anchor_mesh, img_metas, *feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829f43da-9432-4e78-940c-c1a48d501ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.bbox_coder = build_bbox_coder(bbox_coder)\n",
    "        self.use_sigmoid_cls = use_sigmoid\n",
    "        if self.use_sigmoid_cls:\n",
    "            self.cls_out_channels = num_classes\n",
    "        else:\n",
    "            self.cls_out_channels = num_classes + 1\n",
    "        self.nms_pre = nms_pre\n",
    "        self.revert = revert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "9e518a54-97f2-46fa-8e5d-e0eb32c0149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_bboxes_single(cls_score_list,\n",
    "                           bbox_pred_list,\n",
    "                           mlvl_anchors,\n",
    "                           img_metas,\n",
    "                           nms_pre=10000,\n",
    "                           revert=True,\n",
    "                      use_sigmoid_cls=True,\n",
    "                      cls_out_channels=1):\n",
    "        \n",
    "        # if len(mlvl_anchors) > 1:\n",
    "        #     mlvl_anchors = mlvl_anchors[0]\n",
    "        img_shape = img_metas['img_shape']\n",
    "        scale_factor = img_metas['scale_factor']\n",
    "        assert len(cls_score_list) == len(bbox_pred_list) == len(mlvl_anchors)\n",
    "        mlvl_bboxes = []\n",
    "        mlvl_scores = []\n",
    "        for cls_score, bbox_pred, anchors in zip(cls_score_list,\n",
    "                                                 bbox_pred_list, mlvl_anchors):\n",
    "            cls_score = torch.from_numpy(cls_score)\n",
    "            bbox_pred = torch.from_numpy(bbox_pred)\n",
    "            assert cls_score.size()[-2:] == bbox_pred.size()[-2:]\n",
    "            cls_score = cls_score.permute(1, 2,\n",
    "                                          0).reshape(-1, cls_out_channels)\n",
    "            if use_sigmoid_cls:\n",
    "                scores = cls_score.sigmoid()\n",
    "            else:\n",
    "                scores = cls_score.softmax(-1)\n",
    "            bbox_pred = bbox_pred.permute(1, 2, 0).reshape(-1, 4)\n",
    "            if nms_pre > 0 and scores.shape[0] > nms_pre:\n",
    "                # Get maximum scores for foreground classes.\n",
    "                if use_sigmoid_cls:\n",
    "                    max_scores, _ = scores.max(dim=1)\n",
    "                else:\n",
    "                    # remind that we set FG labels to [0, num_class-1]\n",
    "                    # since  v2.0\n",
    "                    # BG cat_id: num_class\n",
    "                    max_scores, _ = scores[:, :-1].max(dim=1)\n",
    "                _, topk_inds = max_scores.topk(nms_pre)\n",
    "                anchors = anchors[topk_inds, :]\n",
    "                bbox_pred = bbox_pred[topk_inds, :]\n",
    "                scores = scores[topk_inds, :]\n",
    "            bboxes = bbox_coder.decode(\n",
    "                anchors, bbox_pred, max_shape=img_shape)\n",
    "            mlvl_bboxes.append(bboxes)\n",
    "            mlvl_scores.append(scores)\n",
    "        mlvl_bboxes = torch.cat(mlvl_bboxes)\n",
    "        mlvl_scores = torch.cat(mlvl_scores)\n",
    "        if self.use_sigmoid_cls:\n",
    "            # Add a dummy background class to the backend when using sigmoid\n",
    "            # remind that we set FG labels to [0, num_class-1] since  v2.0\n",
    "            # BG cat_id: num_class\n",
    "            padding = mlvl_scores.new_zeros(mlvl_scores.shape[0], 1)\n",
    "            mlvl_scores = torch.cat([mlvl_scores, padding], dim=1)\n",
    "        mlvl_centerness = mlvl_scores.new_ones(mlvl_scores.shape[0]).detach()\n",
    "        if revert:\n",
    "            flip = img_metas['flip']\n",
    "            flip_direction = img_metas['flip_direction']\n",
    "            mlvl_bboxes = bbox_revert(mlvl_bboxes, img_shape, scale_factor,\n",
    "                                      flip, flip_direction)\n",
    "        return mlvl_bboxes, mlvl_scores, mlvl_centerness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "cff19432-df4b-4150-9c47-647a4dafe9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bboxes(mlvl_anchors, img_metas, cls_scores, bbox_preds):\n",
    "\n",
    "        assert len(cls_scores) == len(bbox_preds)\n",
    "        num_levels = len(cls_scores)\n",
    "\n",
    "        result_list = []\n",
    "\n",
    "        for img_id in range(len(img_metas)):\n",
    "            cls_score_list = [\n",
    "                cls_scores[i][img_id] for i in range(num_levels)\n",
    "            ]\n",
    "            bbox_pred_list = [\n",
    "                bbox_preds[i][img_id] for i in range(num_levels)\n",
    "            ]\n",
    "            # TODO: hard code. 0 for anchor_list, 1 for valid_flag_list\n",
    "            anchors = mlvl_anchors[0][img_id]\n",
    "            proposals = _get_bboxes_single(cls_score_list, bbox_pred_list,\n",
    "                                                anchors, img_metas[img_id]\n",
    "                                                )\n",
    "            result_list.append(proposals)\n",
    "\n",
    "        \n",
    "        return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "93efcead-ccf6-476c-94c1-53d46b43f43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_metas = {0:final_data['img_metas']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "0cffcdcd-49d5-47c4-ac7a-fe8cbb0c851d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "404054b2-7e3a-4e7b-9bbd-6a7c8304fafc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_bboxes() takes 4 positional arguments but 5 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [412]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dets \u001b[38;5;241m=\u001b[39m \u001b[43mget_bboxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor_mesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_metas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfeats\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_bboxes() takes 4 positional arguments but 5 were given"
     ]
    }
   ],
   "source": [
    "dets = get_bboxes(anchor_mesh, img_metas, *feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "0b62029d-4e8b-4f30-8b0c-90121da3b9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = (0., 0., 0., 0.)\n",
    "stds = (1., 1., 1., 1.)\n",
    "\n",
    "def bbox_decode(bboxes,\n",
    "               pred_bboxes,\n",
    "               max_shape=None,\n",
    "               wh_ratio_clip=16 / 1000):\n",
    "    \n",
    "    assert pred_bboxes.size(0) == bboxes.size(0)\n",
    "    decoded_bboxes = delta2bbox(bboxes, pred_bboxes, means, stds,\n",
    "                                    max_shape, wh_ratio_clip)\n",
    "\n",
    "    return decoded_bboxes\n",
    "\n",
    "def delta2bbox(rois,\n",
    "               deltas,\n",
    "               means=(0., 0., 0., 0.),\n",
    "               stds=(1., 1., 1., 1.),\n",
    "               max_shape=None,\n",
    "               wh_ratio_clip=16 / 1000):\n",
    "    \n",
    "    means = deltas.new_tensor(means).repeat(1, deltas.size(1) // 4)\n",
    "    stds = deltas.new_tensor(stds).repeat(1, deltas.size(1) // 4)\n",
    "    denorm_deltas = deltas * stds + means\n",
    "    dx = denorm_deltas[:, 0::4]\n",
    "    dy = denorm_deltas[:, 1::4]\n",
    "    dw = denorm_deltas[:, 2::4]\n",
    "    dh = denorm_deltas[:, 3::4]\n",
    "    max_ratio = np.abs(np.log(wh_ratio_clip))\n",
    "    dw = dw.clamp(min=-max_ratio, max=max_ratio)\n",
    "    dh = dh.clamp(min=-max_ratio, max=max_ratio)\n",
    "    # Compute center of each roi\n",
    "    px = ((rois[:, 0] + rois[:, 2]) * 0.5).unsqueeze(1).expand_as(dx)\n",
    "    py = ((rois[:, 1] + rois[:, 3]) * 0.5).unsqueeze(1).expand_as(dy)\n",
    "    # Compute width/height of each roi\n",
    "    pw = (rois[:, 2] - rois[:, 0]).unsqueeze(1).expand_as(dw)\n",
    "    ph = (rois[:, 3] - rois[:, 1]).unsqueeze(1).expand_as(dh)\n",
    "    # Use exp(network energy) to enlarge/shrink each roi\n",
    "    gw = pw * dw.exp()\n",
    "    gh = ph * dh.exp()\n",
    "    # Use network energy to shift the center of each roi\n",
    "    gx = px + pw * dx\n",
    "    gy = py + ph * dy\n",
    "    # Convert center-xy/width/height to top-left, bottom-right\n",
    "    x1 = gx - gw * 0.5\n",
    "    y1 = gy - gh * 0.5\n",
    "    x2 = gx + gw * 0.5\n",
    "    y2 = gy + gh * 0.5\n",
    "    if max_shape is not None:\n",
    "        x1 = x1.clamp(min=0, max=max_shape[1])\n",
    "        y1 = y1.clamp(min=0, max=max_shape[0])\n",
    "        x2 = x2.clamp(min=0, max=max_shape[1])\n",
    "        y2 = y2.clamp(min=0, max=max_shape[0])\n",
    "    bboxes = torch.stack([x1, y1, x2, y2], dim=-1).view_as(deltas)\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d914206-eccd-434b-8321-80ed401c6b54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
